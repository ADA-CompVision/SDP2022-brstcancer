{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f6d2ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "import scikitplot as skplt\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d4755d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2093</th>\n",
       "      <th>2094</th>\n",
       "      <th>2095</th>\n",
       "      <th>2096</th>\n",
       "      <th>2097</th>\n",
       "      <th>2098</th>\n",
       "      <th>2099</th>\n",
       "      <th>2100</th>\n",
       "      <th>2101</th>\n",
       "      <th>2102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.512804</td>\n",
       "      <td>0.058938</td>\n",
       "      <td>0.529435</td>\n",
       "      <td>0.070050</td>\n",
       "      <td>0.265008</td>\n",
       "      <td>0.027912</td>\n",
       "      <td>0.885629</td>\n",
       "      <td>0.316553</td>\n",
       "      <td>0.150481</td>\n",
       "      <td>0.259909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967715</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.037648</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.037648</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.543392</td>\n",
       "      <td>0.072460</td>\n",
       "      <td>0.357297</td>\n",
       "      <td>1.824225</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.305774</td>\n",
       "      <td>0.442124</td>\n",
       "      <td>0.238234</td>\n",
       "      <td>0.404805</td>\n",
       "      <td>0.222462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973693</td>\n",
       "      <td>0.038753</td>\n",
       "      <td>0.040148</td>\n",
       "      <td>0.040421</td>\n",
       "      <td>0.038398</td>\n",
       "      <td>0.038753</td>\n",
       "      <td>0.040148</td>\n",
       "      <td>0.040421</td>\n",
       "      <td>0.038398</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.462972</td>\n",
       "      <td>0.023815</td>\n",
       "      <td>0.995784</td>\n",
       "      <td>0.411113</td>\n",
       "      <td>0.291706</td>\n",
       "      <td>0.221538</td>\n",
       "      <td>0.647339</td>\n",
       "      <td>0.891442</td>\n",
       "      <td>0.081914</td>\n",
       "      <td>0.127952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964691</td>\n",
       "      <td>0.043936</td>\n",
       "      <td>0.040705</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.043020</td>\n",
       "      <td>0.043936</td>\n",
       "      <td>0.040705</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.043020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.614602</td>\n",
       "      <td>0.134259</td>\n",
       "      <td>0.112894</td>\n",
       "      <td>0.660946</td>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.710268</td>\n",
       "      <td>0.784855</td>\n",
       "      <td>0.113133</td>\n",
       "      <td>0.261060</td>\n",
       "      <td>0.327604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982214</td>\n",
       "      <td>0.032544</td>\n",
       "      <td>0.031366</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>0.032544</td>\n",
       "      <td>0.031366</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.749940</td>\n",
       "      <td>0.061687</td>\n",
       "      <td>0.795646</td>\n",
       "      <td>0.744609</td>\n",
       "      <td>0.168979</td>\n",
       "      <td>0.680204</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>0.259196</td>\n",
       "      <td>0.411569</td>\n",
       "      <td>0.161880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997227</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>0.021543</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>0.021543</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.021696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815</th>\n",
       "      <td>0.649234</td>\n",
       "      <td>0.032202</td>\n",
       "      <td>0.160830</td>\n",
       "      <td>1.542416</td>\n",
       "      <td>0.286979</td>\n",
       "      <td>0.173201</td>\n",
       "      <td>0.634189</td>\n",
       "      <td>0.147836</td>\n",
       "      <td>0.376638</td>\n",
       "      <td>0.165056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995145</td>\n",
       "      <td>0.028403</td>\n",
       "      <td>0.027558</td>\n",
       "      <td>0.027746</td>\n",
       "      <td>0.027644</td>\n",
       "      <td>0.028403</td>\n",
       "      <td>0.027558</td>\n",
       "      <td>0.027746</td>\n",
       "      <td>0.027644</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7816</th>\n",
       "      <td>0.198588</td>\n",
       "      <td>0.189913</td>\n",
       "      <td>0.593163</td>\n",
       "      <td>2.020908</td>\n",
       "      <td>0.071868</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.311775</td>\n",
       "      <td>0.261614</td>\n",
       "      <td>0.335414</td>\n",
       "      <td>0.229683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977090</td>\n",
       "      <td>0.039669</td>\n",
       "      <td>0.040739</td>\n",
       "      <td>0.041195</td>\n",
       "      <td>0.039638</td>\n",
       "      <td>0.039669</td>\n",
       "      <td>0.040739</td>\n",
       "      <td>0.041195</td>\n",
       "      <td>0.039638</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>0.335369</td>\n",
       "      <td>0.144272</td>\n",
       "      <td>0.238421</td>\n",
       "      <td>1.303674</td>\n",
       "      <td>0.579740</td>\n",
       "      <td>0.189792</td>\n",
       "      <td>0.779709</td>\n",
       "      <td>0.755286</td>\n",
       "      <td>0.638449</td>\n",
       "      <td>0.240480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960393</td>\n",
       "      <td>0.054801</td>\n",
       "      <td>0.057350</td>\n",
       "      <td>0.058956</td>\n",
       "      <td>0.054631</td>\n",
       "      <td>0.054801</td>\n",
       "      <td>0.057350</td>\n",
       "      <td>0.058956</td>\n",
       "      <td>0.054631</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>0.504851</td>\n",
       "      <td>0.039228</td>\n",
       "      <td>0.283918</td>\n",
       "      <td>0.772767</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>0.284417</td>\n",
       "      <td>0.383878</td>\n",
       "      <td>0.030593</td>\n",
       "      <td>0.200283</td>\n",
       "      <td>0.213998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957405</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.068377</td>\n",
       "      <td>0.067482</td>\n",
       "      <td>0.065991</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.068377</td>\n",
       "      <td>0.067482</td>\n",
       "      <td>0.065991</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>0.172708</td>\n",
       "      <td>0.366924</td>\n",
       "      <td>0.370203</td>\n",
       "      <td>2.723996</td>\n",
       "      <td>1.026903</td>\n",
       "      <td>0.141809</td>\n",
       "      <td>0.553321</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>0.576845</td>\n",
       "      <td>0.100579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961967</td>\n",
       "      <td>0.057902</td>\n",
       "      <td>0.055640</td>\n",
       "      <td>0.058397</td>\n",
       "      <td>0.059050</td>\n",
       "      <td>0.057902</td>\n",
       "      <td>0.055640</td>\n",
       "      <td>0.058397</td>\n",
       "      <td>0.059050</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7820 rows × 2103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.512804  0.058938  0.529435  0.070050  0.265008  0.027912  0.885629   \n",
       "1     0.543392  0.072460  0.357297  1.824225  0.011772  0.305774  0.442124   \n",
       "2     0.462972  0.023815  0.995784  0.411113  0.291706  0.221538  0.647339   \n",
       "3     0.614602  0.134259  0.112894  0.660946  0.099556  0.710268  0.784855   \n",
       "4     0.749940  0.061687  0.795646  0.744609  0.168979  0.680204  0.395964   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7815  0.649234  0.032202  0.160830  1.542416  0.286979  0.173201  0.634189   \n",
       "7816  0.198588  0.189913  0.593163  2.020908  0.071868  0.717029  0.311775   \n",
       "7817  0.335369  0.144272  0.238421  1.303674  0.579740  0.189792  0.779709   \n",
       "7818  0.504851  0.039228  0.283918  0.772767  0.015357  0.284417  0.383878   \n",
       "7819  0.172708  0.366924  0.370203  2.723996  1.026903  0.141809  0.553321   \n",
       "\n",
       "             7         8         9  ...      2093      2094      2095  \\\n",
       "0     0.316553  0.150481  0.259909  ...  0.967715  0.038204  0.036946   \n",
       "1     0.238234  0.404805  0.222462  ...  0.973693  0.038753  0.040148   \n",
       "2     0.891442  0.081914  0.127952  ...  0.964691  0.043936  0.040705   \n",
       "3     0.113133  0.261060  0.327604  ...  0.982214  0.032544  0.031366   \n",
       "4     0.259196  0.411569  0.161880  ...  0.997227  0.021783  0.021543   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7815  0.147836  0.376638  0.165056  ...  0.995145  0.028403  0.027558   \n",
       "7816  0.261614  0.335414  0.229683  ...  0.977090  0.039669  0.040739   \n",
       "7817  0.755286  0.638449  0.240480  ...  0.960393  0.054801  0.057350   \n",
       "7818  0.030593  0.200283  0.213998  ...  0.957405  0.068200  0.068377   \n",
       "7819  0.439500  0.576845  0.100579  ...  0.961967  0.057902  0.055640   \n",
       "\n",
       "          2096      2097      2098      2099      2100      2101  2102  \n",
       "0     0.037648  0.037300  0.038204  0.036946  0.037648  0.037300   1.0  \n",
       "1     0.040421  0.038398  0.038753  0.040148  0.040421  0.038398   1.0  \n",
       "2     0.041327  0.043020  0.043936  0.040705  0.041327  0.043020   1.0  \n",
       "3     0.032945  0.032998  0.032544  0.031366  0.032945  0.032998   1.0  \n",
       "4     0.021990  0.021696  0.021783  0.021543  0.021990  0.021696   1.0  \n",
       "...        ...       ...       ...       ...       ...       ...   ...  \n",
       "7815  0.027746  0.027644  0.028403  0.027558  0.027746  0.027644   1.0  \n",
       "7816  0.041195  0.039638  0.039669  0.040739  0.041195  0.039638   1.0  \n",
       "7817  0.058956  0.054631  0.054801  0.057350  0.058956  0.054631   1.0  \n",
       "7818  0.067482  0.065991  0.068200  0.068377  0.067482  0.065991   1.0  \n",
       "7819  0.058397  0.059050  0.057902  0.055640  0.058397  0.059050   1.0  \n",
       "\n",
       "[7820 rows x 2103 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample1 = pd.read_csv(\"Breast_Cancer_Augmented_Positive_Dataset_8k.csv\")\n",
    "df_sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ac0beaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2093</th>\n",
       "      <th>2094</th>\n",
       "      <th>2095</th>\n",
       "      <th>2096</th>\n",
       "      <th>2097</th>\n",
       "      <th>2098</th>\n",
       "      <th>2099</th>\n",
       "      <th>2100</th>\n",
       "      <th>2101</th>\n",
       "      <th>2102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185713</td>\n",
       "      <td>0.129328</td>\n",
       "      <td>0.151128</td>\n",
       "      <td>1.148885</td>\n",
       "      <td>0.355841</td>\n",
       "      <td>0.092020</td>\n",
       "      <td>0.641751</td>\n",
       "      <td>0.588707</td>\n",
       "      <td>0.371998</td>\n",
       "      <td>0.493291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956743</td>\n",
       "      <td>0.050902</td>\n",
       "      <td>0.053116</td>\n",
       "      <td>0.054807</td>\n",
       "      <td>0.050988</td>\n",
       "      <td>0.050902</td>\n",
       "      <td>0.053116</td>\n",
       "      <td>0.054807</td>\n",
       "      <td>0.050988</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.360726</td>\n",
       "      <td>0.373147</td>\n",
       "      <td>0.526488</td>\n",
       "      <td>0.537230</td>\n",
       "      <td>0.136993</td>\n",
       "      <td>0.089766</td>\n",
       "      <td>0.505770</td>\n",
       "      <td>0.140908</td>\n",
       "      <td>0.120453</td>\n",
       "      <td>0.137948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.025075</td>\n",
       "      <td>0.023461</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>0.023263</td>\n",
       "      <td>0.025075</td>\n",
       "      <td>0.023461</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>0.023263</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.157023</td>\n",
       "      <td>0.167137</td>\n",
       "      <td>0.237207</td>\n",
       "      <td>1.282194</td>\n",
       "      <td>0.121771</td>\n",
       "      <td>0.533974</td>\n",
       "      <td>0.293243</td>\n",
       "      <td>0.182768</td>\n",
       "      <td>0.672679</td>\n",
       "      <td>0.248403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973035</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.034887</td>\n",
       "      <td>0.035874</td>\n",
       "      <td>0.034150</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.034887</td>\n",
       "      <td>0.035874</td>\n",
       "      <td>0.034150</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166641</td>\n",
       "      <td>0.767016</td>\n",
       "      <td>0.655124</td>\n",
       "      <td>1.818139</td>\n",
       "      <td>0.512169</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>0.748262</td>\n",
       "      <td>0.146314</td>\n",
       "      <td>0.671473</td>\n",
       "      <td>0.196390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985751</td>\n",
       "      <td>0.030838</td>\n",
       "      <td>0.029879</td>\n",
       "      <td>0.031978</td>\n",
       "      <td>0.031594</td>\n",
       "      <td>0.030838</td>\n",
       "      <td>0.029879</td>\n",
       "      <td>0.031978</td>\n",
       "      <td>0.031594</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111832</td>\n",
       "      <td>0.024164</td>\n",
       "      <td>0.259883</td>\n",
       "      <td>1.798461</td>\n",
       "      <td>0.196784</td>\n",
       "      <td>0.589911</td>\n",
       "      <td>0.254228</td>\n",
       "      <td>0.505094</td>\n",
       "      <td>0.795052</td>\n",
       "      <td>0.341958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995997</td>\n",
       "      <td>0.015538</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>0.015983</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.015538</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>0.015983</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.215518</td>\n",
       "      <td>0.023180</td>\n",
       "      <td>0.034412</td>\n",
       "      <td>1.870273</td>\n",
       "      <td>1.148400</td>\n",
       "      <td>0.741835</td>\n",
       "      <td>0.962309</td>\n",
       "      <td>0.432459</td>\n",
       "      <td>0.227685</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976251</td>\n",
       "      <td>0.040627</td>\n",
       "      <td>0.041627</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.039499</td>\n",
       "      <td>0.040627</td>\n",
       "      <td>0.041627</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.039499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.744583</td>\n",
       "      <td>0.083952</td>\n",
       "      <td>0.237501</td>\n",
       "      <td>1.808680</td>\n",
       "      <td>0.223173</td>\n",
       "      <td>0.336731</td>\n",
       "      <td>0.729377</td>\n",
       "      <td>0.256534</td>\n",
       "      <td>0.373716</td>\n",
       "      <td>0.150315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966343</td>\n",
       "      <td>0.039391</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.036356</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.039391</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.036356</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.200996</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.161329</td>\n",
       "      <td>0.846234</td>\n",
       "      <td>0.154310</td>\n",
       "      <td>0.213440</td>\n",
       "      <td>0.589500</td>\n",
       "      <td>0.088370</td>\n",
       "      <td>0.261969</td>\n",
       "      <td>0.466251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959386</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.047710</td>\n",
       "      <td>0.051098</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.047710</td>\n",
       "      <td>0.051098</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.402526</td>\n",
       "      <td>1.326257</td>\n",
       "      <td>0.970394</td>\n",
       "      <td>1.177871</td>\n",
       "      <td>0.442189</td>\n",
       "      <td>0.288784</td>\n",
       "      <td>0.841492</td>\n",
       "      <td>0.825971</td>\n",
       "      <td>0.238176</td>\n",
       "      <td>0.207474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984141</td>\n",
       "      <td>0.025219</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.024976</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.025219</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.024976</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.771130</td>\n",
       "      <td>0.122112</td>\n",
       "      <td>0.172120</td>\n",
       "      <td>2.294095</td>\n",
       "      <td>0.164705</td>\n",
       "      <td>0.061384</td>\n",
       "      <td>0.619167</td>\n",
       "      <td>0.497287</td>\n",
       "      <td>0.422912</td>\n",
       "      <td>0.131336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964358</td>\n",
       "      <td>0.044209</td>\n",
       "      <td>0.044828</td>\n",
       "      <td>0.046743</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>0.044209</td>\n",
       "      <td>0.044828</td>\n",
       "      <td>0.046743</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.185713  0.129328  0.151128  1.148885  0.355841  0.092020  0.641751   \n",
       "1     0.360726  0.373147  0.526488  0.537230  0.136993  0.089766  0.505770   \n",
       "2     0.157023  0.167137  0.237207  1.282194  0.121771  0.533974  0.293243   \n",
       "3     0.166641  0.767016  0.655124  1.818139  0.512169  0.010876  0.748262   \n",
       "4     0.111832  0.024164  0.259883  1.798461  0.196784  0.589911  0.254228   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.215518  0.023180  0.034412  1.870273  1.148400  0.741835  0.962309   \n",
       "9996  0.744583  0.083952  0.237501  1.808680  0.223173  0.336731  0.729377   \n",
       "9997  1.200996  0.011994  0.161329  0.846234  0.154310  0.213440  0.589500   \n",
       "9998  0.402526  1.326257  0.970394  1.177871  0.442189  0.288784  0.841492   \n",
       "9999  0.771130  0.122112  0.172120  2.294095  0.164705  0.061384  0.619167   \n",
       "\n",
       "             7         8         9  ...      2093      2094      2095  \\\n",
       "0     0.588707  0.371998  0.493291  ...  0.956743  0.050902  0.053116   \n",
       "1     0.140908  0.120453  0.137948  ...  0.995146  0.025075  0.023461   \n",
       "2     0.182768  0.672679  0.248403  ...  0.973035  0.033974  0.034887   \n",
       "3     0.146314  0.671473  0.196390  ...  0.985751  0.030838  0.029879   \n",
       "4     0.505094  0.795052  0.341958  ...  0.995997  0.015538  0.015425   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  0.432459  0.227685  0.058556  ...  0.976251  0.040627  0.041627   \n",
       "9996  0.256534  0.373716  0.150315  ...  0.966343  0.039391  0.037296   \n",
       "9997  0.088370  0.261969  0.466251  ...  0.959386  0.047217  0.047710   \n",
       "9998  0.825971  0.238176  0.207474  ...  0.984141  0.025219  0.024221   \n",
       "9999  0.497287  0.422912  0.131336  ...  0.964358  0.044209  0.044828   \n",
       "\n",
       "          2096      2097      2098      2099      2100      2101  2102  \n",
       "0     0.054807  0.050988  0.050902  0.053116  0.054807  0.050988   0.0  \n",
       "1     0.021841  0.023263  0.025075  0.023461  0.021841  0.023263   0.0  \n",
       "2     0.035874  0.034150  0.033974  0.034887  0.035874  0.034150   0.0  \n",
       "3     0.031978  0.031594  0.030838  0.029879  0.031978  0.031594   0.0  \n",
       "4     0.015983  0.015564  0.015538  0.015425  0.015983  0.015564   0.0  \n",
       "...        ...       ...       ...       ...       ...       ...   ...  \n",
       "9995  0.041772  0.039499  0.040627  0.041627  0.041772  0.039499   0.0  \n",
       "9996  0.036356  0.037387  0.039391  0.037296  0.036356  0.037387   0.0  \n",
       "9997  0.051098  0.049133  0.047217  0.047710  0.051098  0.049133   0.0  \n",
       "9998  0.024976  0.025639  0.025219  0.024221  0.024976  0.025639   0.0  \n",
       "9999  0.046743  0.044648  0.044209  0.044828  0.046743  0.044648   0.0  \n",
       "\n",
       "[10000 rows x 2103 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample2 = pd.read_csv(\"Breast_Cancer_10k_2_Dataset.csv\")\n",
    "df_sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0d5d1801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2093</th>\n",
       "      <th>2094</th>\n",
       "      <th>2095</th>\n",
       "      <th>2096</th>\n",
       "      <th>2097</th>\n",
       "      <th>2098</th>\n",
       "      <th>2099</th>\n",
       "      <th>2100</th>\n",
       "      <th>2101</th>\n",
       "      <th>2102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.512804</td>\n",
       "      <td>0.058938</td>\n",
       "      <td>0.529435</td>\n",
       "      <td>0.070050</td>\n",
       "      <td>0.265008</td>\n",
       "      <td>0.027912</td>\n",
       "      <td>0.885629</td>\n",
       "      <td>0.316553</td>\n",
       "      <td>0.150481</td>\n",
       "      <td>0.259909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967715</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.037648</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.037648</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.543392</td>\n",
       "      <td>0.072460</td>\n",
       "      <td>0.357297</td>\n",
       "      <td>1.824225</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.305774</td>\n",
       "      <td>0.442124</td>\n",
       "      <td>0.238234</td>\n",
       "      <td>0.404805</td>\n",
       "      <td>0.222462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973693</td>\n",
       "      <td>0.038753</td>\n",
       "      <td>0.040148</td>\n",
       "      <td>0.040421</td>\n",
       "      <td>0.038398</td>\n",
       "      <td>0.038753</td>\n",
       "      <td>0.040148</td>\n",
       "      <td>0.040421</td>\n",
       "      <td>0.038398</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.462972</td>\n",
       "      <td>0.023815</td>\n",
       "      <td>0.995784</td>\n",
       "      <td>0.411113</td>\n",
       "      <td>0.291706</td>\n",
       "      <td>0.221538</td>\n",
       "      <td>0.647339</td>\n",
       "      <td>0.891442</td>\n",
       "      <td>0.081914</td>\n",
       "      <td>0.127952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964691</td>\n",
       "      <td>0.043936</td>\n",
       "      <td>0.040705</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.043020</td>\n",
       "      <td>0.043936</td>\n",
       "      <td>0.040705</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.043020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.614602</td>\n",
       "      <td>0.134259</td>\n",
       "      <td>0.112894</td>\n",
       "      <td>0.660946</td>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.710268</td>\n",
       "      <td>0.784855</td>\n",
       "      <td>0.113133</td>\n",
       "      <td>0.261060</td>\n",
       "      <td>0.327604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982214</td>\n",
       "      <td>0.032544</td>\n",
       "      <td>0.031366</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>0.032544</td>\n",
       "      <td>0.031366</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.749940</td>\n",
       "      <td>0.061687</td>\n",
       "      <td>0.795646</td>\n",
       "      <td>0.744609</td>\n",
       "      <td>0.168979</td>\n",
       "      <td>0.680204</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>0.259196</td>\n",
       "      <td>0.411569</td>\n",
       "      <td>0.161880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997227</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>0.021543</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>0.021543</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.021696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.215518</td>\n",
       "      <td>0.023180</td>\n",
       "      <td>0.034412</td>\n",
       "      <td>1.870273</td>\n",
       "      <td>1.148400</td>\n",
       "      <td>0.741835</td>\n",
       "      <td>0.962309</td>\n",
       "      <td>0.432459</td>\n",
       "      <td>0.227685</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976251</td>\n",
       "      <td>0.040627</td>\n",
       "      <td>0.041627</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.039499</td>\n",
       "      <td>0.040627</td>\n",
       "      <td>0.041627</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.039499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.744583</td>\n",
       "      <td>0.083952</td>\n",
       "      <td>0.237501</td>\n",
       "      <td>1.808680</td>\n",
       "      <td>0.223173</td>\n",
       "      <td>0.336731</td>\n",
       "      <td>0.729377</td>\n",
       "      <td>0.256534</td>\n",
       "      <td>0.373716</td>\n",
       "      <td>0.150315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966343</td>\n",
       "      <td>0.039391</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.036356</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.039391</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.036356</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.200996</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.161329</td>\n",
       "      <td>0.846234</td>\n",
       "      <td>0.154310</td>\n",
       "      <td>0.213440</td>\n",
       "      <td>0.589500</td>\n",
       "      <td>0.088370</td>\n",
       "      <td>0.261969</td>\n",
       "      <td>0.466251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959386</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.047710</td>\n",
       "      <td>0.051098</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.047710</td>\n",
       "      <td>0.051098</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.402526</td>\n",
       "      <td>1.326257</td>\n",
       "      <td>0.970394</td>\n",
       "      <td>1.177871</td>\n",
       "      <td>0.442189</td>\n",
       "      <td>0.288784</td>\n",
       "      <td>0.841492</td>\n",
       "      <td>0.825971</td>\n",
       "      <td>0.238176</td>\n",
       "      <td>0.207474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984141</td>\n",
       "      <td>0.025219</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.024976</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.025219</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.024976</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.771130</td>\n",
       "      <td>0.122112</td>\n",
       "      <td>0.172120</td>\n",
       "      <td>2.294095</td>\n",
       "      <td>0.164705</td>\n",
       "      <td>0.061384</td>\n",
       "      <td>0.619167</td>\n",
       "      <td>0.497287</td>\n",
       "      <td>0.422912</td>\n",
       "      <td>0.131336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964358</td>\n",
       "      <td>0.044209</td>\n",
       "      <td>0.044828</td>\n",
       "      <td>0.046743</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>0.044209</td>\n",
       "      <td>0.044828</td>\n",
       "      <td>0.046743</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17820 rows × 2103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.512804  0.058938  0.529435  0.070050  0.265008  0.027912  0.885629   \n",
       "1     0.543392  0.072460  0.357297  1.824225  0.011772  0.305774  0.442124   \n",
       "2     0.462972  0.023815  0.995784  0.411113  0.291706  0.221538  0.647339   \n",
       "3     0.614602  0.134259  0.112894  0.660946  0.099556  0.710268  0.784855   \n",
       "4     0.749940  0.061687  0.795646  0.744609  0.168979  0.680204  0.395964   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.215518  0.023180  0.034412  1.870273  1.148400  0.741835  0.962309   \n",
       "9996  0.744583  0.083952  0.237501  1.808680  0.223173  0.336731  0.729377   \n",
       "9997  1.200996  0.011994  0.161329  0.846234  0.154310  0.213440  0.589500   \n",
       "9998  0.402526  1.326257  0.970394  1.177871  0.442189  0.288784  0.841492   \n",
       "9999  0.771130  0.122112  0.172120  2.294095  0.164705  0.061384  0.619167   \n",
       "\n",
       "             7         8         9  ...      2093      2094      2095  \\\n",
       "0     0.316553  0.150481  0.259909  ...  0.967715  0.038204  0.036946   \n",
       "1     0.238234  0.404805  0.222462  ...  0.973693  0.038753  0.040148   \n",
       "2     0.891442  0.081914  0.127952  ...  0.964691  0.043936  0.040705   \n",
       "3     0.113133  0.261060  0.327604  ...  0.982214  0.032544  0.031366   \n",
       "4     0.259196  0.411569  0.161880  ...  0.997227  0.021783  0.021543   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  0.432459  0.227685  0.058556  ...  0.976251  0.040627  0.041627   \n",
       "9996  0.256534  0.373716  0.150315  ...  0.966343  0.039391  0.037296   \n",
       "9997  0.088370  0.261969  0.466251  ...  0.959386  0.047217  0.047710   \n",
       "9998  0.825971  0.238176  0.207474  ...  0.984141  0.025219  0.024221   \n",
       "9999  0.497287  0.422912  0.131336  ...  0.964358  0.044209  0.044828   \n",
       "\n",
       "          2096      2097      2098      2099      2100      2101  2102  \n",
       "0     0.037648  0.037300  0.038204  0.036946  0.037648  0.037300   1.0  \n",
       "1     0.040421  0.038398  0.038753  0.040148  0.040421  0.038398   1.0  \n",
       "2     0.041327  0.043020  0.043936  0.040705  0.041327  0.043020   1.0  \n",
       "3     0.032945  0.032998  0.032544  0.031366  0.032945  0.032998   1.0  \n",
       "4     0.021990  0.021696  0.021783  0.021543  0.021990  0.021696   1.0  \n",
       "...        ...       ...       ...       ...       ...       ...   ...  \n",
       "9995  0.041772  0.039499  0.040627  0.041627  0.041772  0.039499   0.0  \n",
       "9996  0.036356  0.037387  0.039391  0.037296  0.036356  0.037387   0.0  \n",
       "9997  0.051098  0.049133  0.047217  0.047710  0.051098  0.049133   0.0  \n",
       "9998  0.024976  0.025639  0.025219  0.024221  0.024976  0.025639   0.0  \n",
       "9999  0.046743  0.044648  0.044209  0.044828  0.046743  0.044648   0.0  \n",
       "\n",
       "[17820 rows x 2103 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.concat([df_sample1,df_sample2])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d6a39c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['2048', '2049', '2050','2051','2052','2053'], axis=1)\n",
    "df = df.dropna()\n",
    "df = df[df['2102'] != 2102.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a024d1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "0533fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"2102\",axis=1)\n",
    "Y=df[\"2102\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2a6820ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "19bddeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "sss.get_n_splits(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0a5e8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=sss.split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "607cd664",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"2102\",axis=1)\n",
    "Y=df[\"2102\"]\n",
    "seed = 1\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "2a2c55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7b2ec756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e1529539",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_rf = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "91de2278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7251576d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9a1ff246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8698092031425365"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31697f15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "e9d21daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Recall: 75.00\n",
      "Negative Recall: 96.92\n",
      "Positive Precision: 95.28\n",
      "Negative Precision: 82.37\n",
      "Positive F1-score: 83.93\n",
      "Negative F1-score: 89.06\n"
     ]
    }
   ],
   "source": [
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_recall = recall_score(y_test, y_preds_rf, pos_label=1)\n",
    "negative_recall = recall_score(y_test, y_preds_rf, pos_label=0)\n",
    "\n",
    "print(\"Positive Recall: {:.2f}\".format(positive_recall*100))\n",
    "print(\"Negative Recall: {:.2f}\".format(negative_recall*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_precision = precision_score(y_test, y_preds_rf, pos_label=1)\n",
    "negative_precision = precision_score(y_test, y_preds_rf, pos_label=0)\n",
    "\n",
    "print(\"Positive Precision: {:.2f}\".format(positive_precision*100))\n",
    "print(\"Negative Precision: {:.2f}\".format(negative_precision*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_f1 = f1_score(y_test, y_preds_rf, pos_label=1)\n",
    "negative_f1 = f1_score(y_test, y_preds_rf, pos_label=0)\n",
    "\n",
    "print(\"Positive F1-score: {:.2f}\".format(positive_f1*100))\n",
    "print(\"Negative F1-score: {:.2f}\".format(negative_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0b1807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9d226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b31b362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4ec0501d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.8698092031425365%\n"
     ]
    }
   ],
   "source": [
    "acc_rf = accuracy_score(y_test,y_preds_rf)\n",
    "print('Accuracy of the model: {0}%'.format(acc_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "92dc16f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.8393351800554018%\n"
     ]
    }
   ],
   "source": [
    "f1_rf = f1_score(y_test,y_preds_rf)\n",
    "print('F1 score of the model: {0}%'.format(f1_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "1ddc21c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model: 0.8393351800554018%\n"
     ]
    }
   ],
   "source": [
    "rec_rf = recall_score(y_test,y_preds_rf)\n",
    "print('Recall of the model: {0}%'.format(f1_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "56831ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.8393351800554018%\n"
     ]
    }
   ],
   "source": [
    "pre_rf = precision_score(y_test,y_preds_rf)\n",
    "print('Precision of the model: {0}%'.format(f1_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "54a9972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8ff2cf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toghrul/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c164cb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819304152637486"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "40460346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8822250280583613"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9d2728fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_log_reg = log_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "2f37c9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_log_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "cba6e2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Recall: 73.76\n",
      "Negative Recall: 88.71\n",
      "Positive Precision: 84.42\n",
      "Negative Precision: 80.30\n",
      "Positive F1-score: 78.73\n",
      "Negative F1-score: 84.29\n"
     ]
    }
   ],
   "source": [
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_recall = recall_score(y_test, y_preds_log_reg, pos_label=1)\n",
    "negative_recall = recall_score(y_test, y_preds_log_reg, pos_label=0)\n",
    "\n",
    "print(\"Positive Recall: {:.2f}\".format(positive_recall*100))\n",
    "print(\"Negative Recall: {:.2f}\".format(negative_recall*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_precision = precision_score(y_test, y_preds_log_reg, pos_label=1)\n",
    "negative_precision = precision_score(y_test, y_preds_log_reg, pos_label=0)\n",
    "\n",
    "print(\"Positive Precision: {:.2f}\".format(positive_precision*100))\n",
    "print(\"Negative Precision: {:.2f}\".format(negative_precision*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_f1 = f1_score(y_test, y_preds_log_reg, pos_label=1)\n",
    "negative_f1 = f1_score(y_test, y_preds_log_reg, pos_label=0)\n",
    "\n",
    "print(\"Positive F1-score: {:.2f}\".format(positive_f1*100))\n",
    "print(\"Negative F1-score: {:.2f}\".format(negative_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "2ace19a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.819304152637486%\n"
     ]
    }
   ],
   "source": [
    "acc_log_reg = accuracy_score(y_test,y_preds_log_reg)\n",
    "print('Accuracy of the model: {0}%'.format(acc_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "440e4929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.7873183619550859%\n"
     ]
    }
   ],
   "source": [
    "f1_log_reg = f1_score(y_test,y_preds_log_reg)\n",
    "print('F1 score of the model: {0}%'.format(f1_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "af8dc3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model: 0.7376237623762376%\n"
     ]
    }
   ],
   "source": [
    "rec_log_reg = recall_score(y_test,y_preds_log_reg)\n",
    "print('Recall of the model: {0}%'.format(rec_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5150d29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.8441926345609065%\n"
     ]
    }
   ],
   "source": [
    "pre_log_reg = precision_score(y_test,y_preds_log_reg)\n",
    "print('Precision of the model: {0}%'.format(pre_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7df8fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ca955267",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b6626767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2d2f7705",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_knn = KNN.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ddd3bf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7d73f156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Recall: 75.50\n",
      "Negative Recall: 88.91\n",
      "Positive Precision: 84.96\n",
      "Negative Precision: 81.39\n",
      "Positive F1-score: 79.95\n",
      "Negative F1-score: 84.99\n"
     ]
    }
   ],
   "source": [
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_recall = recall_score(y_test, y_preds_knn, pos_label=1)\n",
    "negative_recall = recall_score(y_test, y_preds_knn, pos_label=0)\n",
    "\n",
    "print(\"Positive Recall: {:.2f}\".format(positive_recall*100))\n",
    "print(\"Negative Recall: {:.2f}\".format(negative_recall*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_precision = precision_score(y_test, y_preds_knn, pos_label=1)\n",
    "negative_precision = precision_score(y_test, y_preds_knn, pos_label=0)\n",
    "\n",
    "print(\"Positive Precision: {:.2f}\".format(positive_precision*100))\n",
    "print(\"Negative Precision: {:.2f}\".format(negative_precision*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_f1 = f1_score(y_test, y_preds_knn, pos_label=1)\n",
    "negative_f1 = f1_score(y_test, y_preds_knn, pos_label=0)\n",
    "\n",
    "print(\"Positive F1-score: {:.2f}\".format(positive_f1*100))\n",
    "print(\"Negative F1-score: {:.2f}\".format(negative_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "dd5eb3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8920454545454546"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c79369c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8282828282828283"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d4a46a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.8282828282828283%\n"
     ]
    }
   ],
   "source": [
    "acc_KNN = accuracy_score(y_test,y_preds_knn)\n",
    "print('Accuracy of the model: {0}%'.format(acc_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d91cfee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.799475753604194%\n"
     ]
    }
   ],
   "source": [
    "f1_KNN = f1_score(y_test,y_preds_knn)\n",
    "print('F1 score of the model: {0}%'.format(f1_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "d440c6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model: 0.754950495049505%\n"
     ]
    }
   ],
   "source": [
    "rec_KNN = recall_score(y_test,y_preds_knn)\n",
    "print('Recall of the model: {0}%'.format(rec_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5501b536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.8495821727019499%\n"
     ]
    }
   ],
   "source": [
    "pre_KNN = precision_score(y_test,y_preds_knn)\n",
    "print('Precision of the model: {0}%'.format(pre_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "23a9d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "4a4840e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d9553fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_ds = decision_tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "711a38a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "168b8966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Recall: 77.97\n",
      "Negative Recall: 75.56\n",
      "Positive Precision: 72.58\n",
      "Negative Precision: 80.53\n",
      "Positive F1-score: 75.18\n",
      "Negative F1-score: 77.97\n"
     ]
    }
   ],
   "source": [
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_recall = recall_score(y_test, y_preds_ds, pos_label=1)\n",
    "negative_recall = recall_score(y_test, y_preds_ds, pos_label=0)\n",
    "\n",
    "print(\"Positive Recall: {:.2f}\".format(positive_recall*100))\n",
    "print(\"Negative Recall: {:.2f}\".format(negative_recall*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_precision = precision_score(y_test, y_preds_ds, pos_label=1)\n",
    "negative_precision = precision_score(y_test, y_preds_ds, pos_label=0)\n",
    "\n",
    "print(\"Positive Precision: {:.2f}\".format(positive_precision*100))\n",
    "print(\"Negative Precision: {:.2f}\".format(negative_precision*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_f1 = f1_score(y_test, y_preds_ds, pos_label=1)\n",
    "negative_f1 = f1_score(y_test, y_preds_ds, pos_label=0)\n",
    "\n",
    "print(\"Positive F1-score: {:.2f}\".format(positive_f1*100))\n",
    "print(\"Negative F1-score: {:.2f}\".format(negative_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e1a70a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "51646094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7665544332210998"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "25f3b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.7665544332210998%\n"
     ]
    }
   ],
   "source": [
    "acc_decision_tree = accuracy_score(y_test,y_preds_ds)\n",
    "print('Accuracy of the model: {0}%'.format(acc_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7828e087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.7517899761336516%\n"
     ]
    }
   ],
   "source": [
    "f1_decision_tree = f1_score(y_test,y_preds_ds)\n",
    "print('F1 score of the model: {0}%'.format(f1_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a4ae531e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model: 0.7797029702970297%\n"
     ]
    }
   ],
   "source": [
    "rec_decision_tree = recall_score(y_test,y_preds_ds)\n",
    "print('Recall of the model: {0}%'.format(rec_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "fb8091c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.7258064516129032%\n"
     ]
    }
   ],
   "source": [
    "pre_decision_tree = precision_score(y_test,y_preds_ds)\n",
    "print('Precision of the model: {0}%'.format(pre_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "cfa3b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "143e759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "linear_svm = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ff47f682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4fada9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toghrul/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6a47830b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8850308641975309"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "df3980c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_svc = svc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "f5068f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_svc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "9bad9a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Recall: 69.55\n",
      "Negative Recall: 98.56\n",
      "Positive Precision: 97.57\n",
      "Negative Precision: 79.60\n",
      "Positive F1-score: 81.21\n",
      "Negative F1-score: 88.07\n"
     ]
    }
   ],
   "source": [
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_recall = recall_score(y_test, y_preds_svc, pos_label=1)\n",
    "negative_recall = recall_score(y_test, y_preds_svc, pos_label=0)\n",
    "\n",
    "print(\"Positive Recall: {:.2f}\".format(positive_recall*100))\n",
    "print(\"Negative Recall: {:.2f}\".format(negative_recall*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_precision = precision_score(y_test, y_preds_svc, pos_label=1)\n",
    "negative_precision = precision_score(y_test, y_preds_svc, pos_label=0)\n",
    "\n",
    "print(\"Positive Precision: {:.2f}\".format(positive_precision*100))\n",
    "print(\"Negative Precision: {:.2f}\".format(negative_precision*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_f1 = f1_score(y_test, y_preds_svc, pos_label=1)\n",
    "negative_f1 = f1_score(y_test, y_preds_svc, pos_label=0)\n",
    "\n",
    "print(\"Positive F1-score: {:.2f}\".format(positive_f1*100))\n",
    "print(\"Negative F1-score: {:.2f}\".format(negative_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "25753c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.8540965207631874%\n"
     ]
    }
   ],
   "source": [
    "acc_svc = accuracy_score(y_test,y_preds_svc)\n",
    "print('Accuracy of the model: {0}%'.format(acc_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "8a2594a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.8121387283236994%\n"
     ]
    }
   ],
   "source": [
    "f1_svc = f1_score(y_test,y_preds_svc)\n",
    "print('F1 score of the model: {0}%'.format(f1_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6a6fef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score of the model: 0.6955445544554455%\n"
     ]
    }
   ],
   "source": [
    "rec_svc = recall_score(y_test,y_preds_svc)\n",
    "print('Recall score of the model: {0}%'.format(rec_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "12354a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.9756944444444444%\n"
     ]
    }
   ],
   "source": [
    "pre_svc = precision_score(y_test,y_preds_svc)\n",
    "print('Precision of the model: {0}%'.format(pre_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7bef0b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8877665544332211"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svm.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "0c9819d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_linear_svc = linear_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "7d9a2faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_linear_svc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "244f40ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.8305274971941639%\n"
     ]
    }
   ],
   "source": [
    "acc_linear_svc = accuracy_score(y_test,y_preds_linear_svc)\n",
    "print('Accuracy of the model: {0}%'.format(acc_linear_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "168fe978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.7945578231292516%\n"
     ]
    }
   ],
   "source": [
    "f1_linear_svc = f1_score(y_test,y_preds_linear_svc)\n",
    "print('F1 score of the model: {0}%'.format(f1_linear_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b8cac1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model: 0.7227722772277227%\n"
     ]
    }
   ],
   "source": [
    "rec_linear_svc = recall_score(y_test,y_preds_linear_svc)\n",
    "print('Recall of the model: {0}%'.format(rec_linear_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "fa310e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.8821752265861027%\n"
     ]
    }
   ],
   "source": [
    "pre_linear_svc = precision_score(y_test,y_preds_linear_svc)\n",
    "print('Precision of the model: {0}%'.format(pre_linear_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b5075489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.869809</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.952830</td>\n",
       "      <td>0.839335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.854097</td>\n",
       "      <td>0.695545</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>0.812139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighbour Clasifier</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.754950</td>\n",
       "      <td>0.849582</td>\n",
       "      <td>0.799476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.830527</td>\n",
       "      <td>0.722772</td>\n",
       "      <td>0.882175</td>\n",
       "      <td>0.794558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.737624</td>\n",
       "      <td>0.844193</td>\n",
       "      <td>0.787318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.766554</td>\n",
       "      <td>0.779703</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.751790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Accuracy    Recall  Precision  F1 score\n",
       "0  Random Forest Classifier  0.869809  0.750000   0.952830  0.839335\n",
       "4                       SVC  0.854097  0.695545   0.975694  0.812139\n",
       "2      KNeighbour Clasifier  0.828283  0.754950   0.849582  0.799476\n",
       "5                Linear SVC  0.830527  0.722772   0.882175  0.794558\n",
       "1       Logistic Regression  0.819304  0.737624   0.844193  0.787318\n",
       "3             Decision Tree  0.766554  0.779703   0.725806  0.751790"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Models = pd.DataFrame({\n",
    "    'Model' : ['Random Forest Classifier', 'Logistic Regression', 'KNeighbour Clasifier',\n",
    "              'Decision Tree', 'SVC', 'Linear SVC'],\n",
    "    'Accuracy' : [acc_rf, acc_log_reg, acc_KNN, acc_decision_tree, acc_svc, acc_linear_svc],\n",
    "    'Recall' : [rec_rf, rec_log_reg, rec_KNN, rec_decision_tree, rec_svc, rec_linear_svc],\n",
    "    'Precision' : [pre_rf, pre_log_reg, pre_KNN, pre_decision_tree, pre_svc, pre_linear_svc],\n",
    "    'F1 score' : [f1_rf, f1_log_reg, f1_KNN, f1_decision_tree, f1_svc, f1_linear_svc]\n",
    "})\n",
    "Models.sort_values(by = \"F1 score\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "0f3aad38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Models.sort_values(by = \"F1 score\", ascending = False).plot(kind = \"bar\", color = [\"blue\", 'red','green','yellow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdff762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "0860b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['0'] = df['0'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ce3e457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "24d172ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight=int(y_train.value_counts()[0]/y_train.value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "0bfff876",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost=xgb.XGBClassifier(scale_pos_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "698bd520",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_param_grid={\n",
    "    'learning_rate':[0.05,0.1,0.15,0.2,0.25,0.3],\n",
    "    'max_depth'    :[1,2,3,4,5,6,7,8,9,10],\n",
    "    'min_child_weight':[1,3,5,7],\n",
    "    'colsample_bytree':[0.3,0.4,0.5,0.6,0.7],\n",
    "    'gamma':[0.0,0.1,0.2,0.3,0.4,0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "598aa5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2b6687a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "3029cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold=StratifiedKFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d4bd393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsXGoost=RandomizedSearchCV(estimator=XGBoost,param_distributions=xgboost_param_grid,random_state=3,scoring = \"roc_auc\", \n",
    "                                     cv =kfold,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2e8b6042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           import...\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5, 0.6,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10],\n",
       "                                        'min_child_weight': [1, 3, 5, 7]},\n",
       "                   random_state=3, scoring='roc_auc')"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsXGoost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5c40447f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9167395399887157"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBOOST_best = gsXGoost.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsXGoost.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ac5caffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = XGBOOST_best.predict(X_test)\n",
    "y_pred = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "fb2d1013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Recall: 79.95\n",
      "Negative Recall: 95.48\n",
      "Positive Precision: 93.62\n",
      "Negative Precision: 85.16\n",
      "Positive F1-score: 86.25\n",
      "Negative F1-score: 90.03\n"
     ]
    }
   ],
   "source": [
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "negative_recall = recall_score(y_test, y_pred, pos_label=0)\n",
    "\n",
    "print(\"Positive Recall: {:.2f}\".format(positive_recall*100))\n",
    "print(\"Negative Recall: {:.2f}\".format(negative_recall*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "negative_precision = precision_score(y_test, y_pred, pos_label=0)\n",
    "\n",
    "print(\"Positive Precision: {:.2f}\".format(positive_precision*100))\n",
    "print(\"Negative Precision: {:.2f}\".format(negative_precision*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "negative_f1 = f1_score(y_test, y_pred, pos_label=0)\n",
    "\n",
    "print(\"Positive F1-score: {:.2f}\".format(positive_f1*100))\n",
    "print(\"Negative F1-score: {:.2f}\".format(negative_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b5c707b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8843995510662177"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0249c04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8624833110814419"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "74e4238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.8843995510662177%\n"
     ]
    }
   ],
   "source": [
    "acc_xgboost = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy of the model: {0}%'.format(acc_xgboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e07445a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.936231884057971%\n"
     ]
    }
   ],
   "source": [
    "pre_xgboost = precision_score(y_test,y_pred)\n",
    "print('Precision of the model: {0}%'.format(pre_xgboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c0bdefb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model: 0.7995049504950495%\n"
     ]
    }
   ],
   "source": [
    "rec_xgboost = recall_score(y_test,y_pred)\n",
    "print('Recall of the model: {0}%'.format(rec_xgboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "2b2573a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.8624833110814419%\n"
     ]
    }
   ],
   "source": [
    "f1_xgboost = f1_score(y_test,y_pred)\n",
    "print('F1 score of the model: {0}%'.format(f1_xgboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "8881a7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.884400</td>\n",
       "      <td>0.799505</td>\n",
       "      <td>0.936232</td>\n",
       "      <td>0.862483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.869809</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.952830</td>\n",
       "      <td>0.839335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.854097</td>\n",
       "      <td>0.695545</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>0.812139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighbour Clasifier</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.754950</td>\n",
       "      <td>0.849582</td>\n",
       "      <td>0.799476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.737624</td>\n",
       "      <td>0.844193</td>\n",
       "      <td>0.787318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.766554</td>\n",
       "      <td>0.779703</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.751790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Accuracy    Recall  Precision  F1 score\n",
       "5                   XGBoost  0.884400  0.799505   0.936232  0.862483\n",
       "0  Random Forest Classifier  0.869809  0.750000   0.952830  0.839335\n",
       "4                       SVC  0.854097  0.695545   0.975694  0.812139\n",
       "2      KNeighbour Clasifier  0.828283  0.754950   0.849582  0.799476\n",
       "1       Logistic Regression  0.819304  0.737624   0.844193  0.787318\n",
       "3             Decision Tree  0.766554  0.779703   0.725806  0.751790"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Models = pd.DataFrame({\n",
    "    'Model' : ['Random Forest Classifier', 'Logistic Regression', 'KNeighbour Clasifier',\n",
    "              'Decision Tree', 'SVC', 'XGBoost'],\n",
    "    'Accuracy' : [acc_rf, acc_log_reg, acc_KNN, acc_decision_tree, acc_svc,acc_xgboost],\n",
    "    'Recall' : [rec_rf, rec_log_reg, rec_KNN, rec_decision_tree, rec_svc,rec_xgboost],\n",
    "    'Precision' : [pre_rf, pre_log_reg, pre_KNN, pre_decision_tree, pre_svc,pre_xgboost],\n",
    "    'F1 score' : [f1_rf, f1_log_reg, f1_KNN, f1_decision_tree, f1_svc, f1_xgboost]\n",
    "})\n",
    "Models.sort_values(by = \"F1 score\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9a522588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGYCAYAAACQz+KaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvMUlEQVR4nO3de1wVdf7H8fdB8IAXICVQDBFDk/JWUC1eMm8YtpZZq2Z5WbVdpPKhlP4y97deVqNty8hKNAVJN83M8mFKKtlmmlZK4vpLy1IKTJDUAq8gML8/XM9jT6Cdg+BX6PXsMY9HZ+Y7M58Z0fPmO9+ZsVmWZQkAAMAQD9MFAACA3zbCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjPE0X4Iry8nIdPnxYjRs3ls1mM10OAABwgWVZOnHihIKDg+XhcfH+j1oRRg4fPqyQkBDTZQAAgCrIzc3Vddddd9HltSKMNG7cWNL5g/H19TVcDQAAcEVRUZFCQkIc3+MXUyvCyIVLM76+voQRAABqmV8bYsEAVgAAYJTbYeTjjz/WgAEDFBwcLJvNptWrV//qOps3b1ZkZKS8vb3VunVrzZ8/vyq1AgCAOsjtMHLq1Cl16tRJr7zyikvts7Oz1b9/f3Xv3l27du3S008/rfHjx2vVqlVuFwsAAOoet8eMxMbGKjY21uX28+fPV8uWLZWUlCRJioiI0M6dO/X888/r/vvvd3f3AIA6qKysTOfOnTNdBtzk5eWlevXqXfZ2anwA6/bt2xUTE+M0r1+/fkpJSdG5c+fk5eVV0yUAAK5SlmUpPz9fP//8s+lSUEX+/v5q1qzZZT0HrMbDSH5+voKCgpzmBQUFqbS0VEePHlXz5s0rrFNcXKzi4mLH56KiopouEwBgwIUgEhgYqAYNGvBgy1rEsiydPn1aBQUFklTp97mrrsitvb/84bIsq9L5FyQmJmrGjBk1XhcAwJyysjJHEGnatKnpclAFPj4+kqSCggIFBgZW+ZJNjd/a26xZM+Xn5zvNKygokKen50V/+KZMmaLCwkLHlJubW9NlAgCusAtjRBo0aGC4ElyOC39+lzPmp8Z7RqKjo/Xee+85zdu4caOioqIuOl7EbrfLbrfXdGkAgKsAl2Zqt+r483O7Z+TkyZPKyspSVlaWpPO37mZlZSknJ0fS+V6NESNGONrHxcXp+++/V0JCgvbt26fU1FSlpKToySefvOziAQBA7ed2z8jOnTvVs2dPx+eEhARJ0siRI5WWlqa8vDxHMJGksLAwpaena+LEiXr11VcVHBysuXPnclsvAACQVIUwcueddzoGoFYmLS2twrwePXroiy++cHdXAIDfqCt95eYSX2uXtG3bNnXv3l19+/bV+vXrq7eo3xDeTQMAQBWlpqbq8ccf19atW52uClxptf2BcYQRAACq4NSpU3rrrbc0btw4/f73v69wZWDNmjWKioqSt7e3AgICNGjQIMey4uJiTZ48WSEhIbLb7WrTpo1SUlIknb/C4O/v77St1atXOw0UnT59ujp37qzU1FS1bt1adrtdlmVp/fr16tatm/z9/dW0aVP9/ve/14EDB5y2dejQIQ0dOlRNmjRRw4YNFRUVpc8++0zfffedPDw8tHPnTqf2L7/8skJDQy95VeRyXZHnjAAwxzbDtf5ua1rN/UMD1EUrVqzQDTfcoBtuuEEPP/ywHn/8cf3v//6vbDab1q1bp0GDBmnq1KlaunSpSkpKtG7dOse6I0aM0Pbt2zV37lx16tRJ2dnZOnr0qFv7//bbb/XWW29p1apVjud7nDp1SgkJCerQoYNOnTqlv/71r7rvvvuUlZUlDw8PnTx5Uj169FCLFi20Zs0aNWvWTF988YXKy8vVqlUr9enTR4sXL1ZUVJRjP4sXL9aoUaNq9K4nwggAAFWQkpKihx9+WJJ011136eTJk9q0aZP69Omj2bNna+jQoU4P8OzUqZMkaf/+/XrrrbeUkZGhPn36SJJat27t9v5LSkq0dOlSXXvttY55v7w5JCUlRYGBgdq7d6/at2+vZcuW6ccff9SOHTvUpEkTSVJ4eLij/dixYxUXF6c5c+bIbrdr9+7dysrK0jvvvON2fe7gMg0AAG76+uuv9fnnn2vo0KGSJE9PTw0ZMkSpqamSpKysLPXu3bvSdbOyslSvXj316NHjsmoIDQ11CiKSdODAAQ0bNkytW7eWr6+vwsLCJMkxniUrK0s333yzI4j80sCBA+Xp6al3331X0vkxMT179lSrVq0uq9ZfQ88IAABuSklJUWlpqVq0aOGYZ1mWvLy89NNPPzkek16ZSy2TJA8PjwrjMyoboNqwYcMK8wYMGKCQkBAtXLhQwcHBKi8vV/v27VVSUuLSvuvXr6/hw4dr8eLFGjRokJYtW6akpKRLrlMd6BkBAMANpaWlWrJkiV544QXHQ0CzsrK0e/duhYaG6o033lDHjh21adOmStfv0KGDysvLtXnz5kqXX3vttTpx4oROnTrlmHfhQaOXcuzYMe3bt09/+ctf1Lt3b0VEROinn35yatOxY0dlZWXp+PHjF93O2LFj9cEHH2jevHk6d+6c08DbmkLPCAAAbli7dq1++uknjRkzRn5+fk7LHnjgAaWkpOjFF19U7969df3112vo0KEqLS3V+++/r8mTJ6tVq1YaOXKkRo8e7RjA+v3336ugoECDBw/W7bffrgYNGujpp5/W448/rs8//7zSZ3j90jXXXKOmTZvqtddeU/PmzZWTk6OnnnrKqc2DDz6oZ555RgMHDlRiYqKaN2+uXbt2KTg4WNHR0ZKkiIgI/e53v9P//M//aPTo0b/am1Id6BkBAFx1LOvKTu5ISUlRnz59KgQR6fwA0qysLPn6+mrlypVas2aNOnfurF69eumzzz5ztEtOTtYDDzyg+Ph4tWvXTo888oijJ6RJkyb65z//qfT0dHXo0EHLly/X9OnTf7UuDw8Pvfnmm8rMzFT79u01ceJE/eMf/3BqU79+fW3cuFGBgYHq37+/OnTooGeffbbC23bHjBmjkpISjR492r2TU0U2qyZvHK4mRUVF8vPzU2FhoXx9fU2XA9Qq3NqLq9XZs2eVnZ2tsLAweXt7my4H/2X27Nl68803tWfPnl9te6k/R1e/v+kZAQAAks6/DHfHjh16+eWXNX78+Cu2X8aM4KrEb/MAcOU99thjWr58uQYOHHjFLtFIhBEAAPAfaWlpLg2WrW5cpgEAAEYRRgAAgFGEEQAAYBRhBAAAGMUA1mrk6h0gEneBAABwAT0jAADUQq1atXJ6iZ3NZtPq1auN1XM5CCMAALhp1KhRstlsstls8vT0VMuWLTVu3LgKL6aDa7hMAwC4+thcv+xdLarwZpS77rpLixcvVmlpqfbu3avRo0fr559/1vLly2ugwLqNnhEAAKrAbrerWbNmuu666xQTE6MhQ4Zo48aNjuWLFy9WRESEvL291a5dO82bN89p/UOHDmno0KFq0qSJGjZsqKioKMfL9A4cOKB7771XQUFBatSokW699VZ98MEHV/T4riR6RgAAuEwHDx7U+vXr5eXlJUlauHChpk2bpldeeUU333yzdu3apUceeUQNGzbUyJEjdfLkSfXo0UMtWrTQmjVr1KxZM33xxRcqLy+XdP4dMf3799esWbPk7e2t119/XQMGDNDXX3+tli1bmjzUGkEYAQCgCtauXatGjRqprKxMZ8+elSTNmTNHkvS3v/1NL7zwggYNGiRJCgsL0969e7VgwQKNHDlSy5Yt048//qgdO3aoSZMmkqTw8HDHtjt16qROnTo5Ps+aNUvvvvuu1qxZo8cee+xKHeIVQxgBAKAKevbsqeTkZJ0+fVqLFi3S/v379fjjj+vHH39Ubm6uxowZo0ceecTRvrS0VH5+fpKkrKws3XzzzY4g8kunTp3SjBkztHbtWh0+fFilpaU6c+aMcnJyrsixXWmEEQAAqqBhw4aO3oy5c+eqZ8+emjFjhqPnYuHChbr99tud1qlXr54kycfH55LbnjRpkjZs2KDnn39e4eHh8vHx0QMPPKCSkpIaOBLzCCMAAFSDadOmKTY2VuPGjVOLFi108OBBPfTQQ5W27dixoxYtWqTjx49X2juyZcsWjRo1Svfdd5+k82NIvvvuu5os3yjupgEAoBrceeeduummm/TMM89o+vTpSkxM1EsvvaT9+/drz549Wrx4sWNMyYMPPqhmzZpp4MCB+uSTT3Tw4EGtWrVK27dvl3R+/Mg777yjrKws7d69W8OGDXMMbq2LCCMAAFSThIQELVy4UP369dOiRYuUlpamDh06qEePHkpLS1NYWJgkqX79+tq4caMCAwPVv39/dejQQc8++6zjMs6LL76oa665Rl26dNGAAQPUr18/3XLLLSYPrUbZLKsKT3q5woqKiuTn56fCwkL5+vqaLueieDdN9XH1XHIefx3nElers2fPKjs7W2FhYfL29jZdDqroUn+Orn5/0zMCAACMIowAAACjCCMAAMAowggAADCKMAIAAIz6TT/0zNU3VF/99xsBAFB70TMCAACMIowAAACjCCMAAMAowggAALVAq1atlJSUVO1trwa/6QGsAICrkzuv16gO7r4OYdSoUXr99dclSZ6engoJCdGgQYM0Y8YMNWzYsCZK1I4dO1zetjttrwaEEVw2V+9KkrgzCUDdcdddd2nx4sU6d+6ctmzZorFjx+rUqVNKTk52anfu3Dl5eXld9v6uvfbaGml7NeAyDQAAVWC329WsWTOFhIRo2LBheuihh7R69WpNnz5dnTt3Vmpqqlq3bi273S7LslRYWKg//elPCgwMlK+vr3r16qXdu3c7bXPNmjWKioqSt7e3AgICNGjQIMeyX156mT59ulq2bCm73a7g4GCNHz/+om1zcnJ07733qlGjRvL19dXgwYN15MgRp2117txZS5cuVatWreTn56ehQ4fqxIkT1X/iKkEYMcbm4gQAqA18fHx07tw5SdK3336rt956S6tWrVJWVpYk6e6771Z+fr7S09OVmZmpW265Rb1799bx48clSevWrdOgQYN09913a9euXdq0aZOioqIq3dfbb7+tF198UQsWLNA333yj1atXq0OHDpW2tSxLAwcO1PHjx7V582ZlZGTowIEDGjJkiFO7AwcOaPXq1Vq7dq3Wrl2rzZs369lnn62ms3NpXKYBAOAyff7551q2bJl69+4tSSopKdHSpUsdl0s+/PBD7dmzRwUFBbLb7ZKk559/XqtXr9bbb7+tP/3pT5o9e7aGDh2qGTNmOLbbqVOnSveXk5OjZs2aqU+fPvLy8lLLli112223Vdr2gw8+0L///W9lZ2crJCREkrR06VLddNNN2rFjh2699VZJUnl5udLS0tS4cWNJ0vDhw7Vp0ybNnj27Gs7QpdEzAgBAFaxdu1aNGjWSt7e3oqOjdccdd+jll1+WJIWGhjqN28jMzNTJkyfVtGlTNWrUyDFlZ2frwIEDkqSsrCxHmPk1f/jDH3TmzBm1bt1ajzzyiN59912VlpZW2nbfvn0KCQlxBBFJuvHGG+Xv7699+/Y55rVq1coRRCSpefPmKigocP2EXAZ6RoCrCK8oAGqPnj17Kjk5WV5eXgoODnYapPrLO1nKy8vVvHlzffTRRxW24+/vL+n8ZR5XhYSE6Ouvv1ZGRoY++OADxcfH6x//+Ic2b95cYbCsZVmyVfKPyy/n/3I9m82m8vJyl2u6HPSMAABQBQ0bNlR4eLhCQ0N/9W6ZW265Rfn5+fL09FR4eLjTFBAQIEnq2LGjNm3a5PL+fXx8dM8992ju3Ln66KOPtH37du3Zs6dCuxtvvFE5OTnKzc11zNu7d68KCwsVERHh8v5qEj0jAOACd5574e4zK1D39enTR9HR0Ro4cKD+/ve/64YbbtDhw4eVnp6ugQMHKioqStOmTVPv3r11/fXXa+jQoSotLdX777+vyZMnV9heWlqaysrKdPvtt6tBgwZaunSpfHx8FBoaWum+O3bsqIceekhJSUkqLS1VfHy8evTocdEBslcaPSMAANQwm82m9PR03XHHHRo9erTatm2roUOH6rvvvlNQUJAk6c4779TKlSu1Zs0ade7cWb169dJnn31W6fb8/f21cOFCde3a1dGj8t5776lp06aV7nv16tW65pprdMcdd6hPnz5q3bq1VqxYUaPH7A6bZV39V5+Liork5+enwsJC+fr6Vtt2q/v6vHu/Obnc0uVtmlITDz1z9VzWtd9Aa2LMyG/1XFY3ekaqz4VzGdowVPO7zldAi4BK++mjgq+O39pxaWfPnlV2drbCwsLk7e3ttMzV7296RgAAgFGMGUEt586D4fhtFQCuRvSMAAAAowgjAADAKMIIAAAwijEjAOoknmYL1B70jAAAAKMIIwAAwCgu0wAALqomHmoI/BI9IwAAwKgqhZF58+Y5HvsaGRmpLVu2XLL9G2+8oU6dOqlBgwZq3ry5/vjHP+rYsWNVKhhATbG5OAE1Lyr4Vrn+M1kdk3tGjRolm81WYfr2228lSR9//LEGDBig4OBgx7thcHFuh5EVK1ZowoQJmjp1qnbt2qXu3bsrNjZWOTk5lbbfunWrRowYoTFjxujLL7/UypUrtWPHDo0dO/ayiwcAwJS77rpLeXl5TlNYWJgk6dSpU+rUqZNeeeUVw1VWzrIslZaWmi7Dwe0wMmfOHI0ZM0Zjx45VRESEkpKSFBISouTk5Erbf/rpp2rVqpXGjx+vsLAwdevWTX/+85+1c+fOyy4eAABT7Ha7mjVr5jTVq1dPkhQbG6tZs2Zp0KBBLm9v9+7d6tmzpxo3bixfX19FRkY6fVd+8skn6tGjhxo0aKBrrrlG/fr1008//SRJKi4u1vjx4xUYGChvb29169ZNO3bscKz70UcfyWazacOGDYqKipLdbteWLVtkWZaee+45tW7dWj4+PurUqZPefvvtajpDrnMrjJSUlCgzM1MxMTFO82NiYrRt27ZK1+nSpYsOHTqk9PR0WZalI0eO6O2339bdd99d9aoBAKhjHnroIV133XXasWOHMjMz9dRTT8nLy0uSlJWVpd69e+umm27S9u3btXXrVg0YMEBlZWWSpMmTJ2vVqlV6/fXX9cUXXyg8PFz9+vXT8ePHnfYxefJkJSYmat++ferYsaP+8pe/aPHixUpOTtaXX36piRMn6uGHH9bmzZuv6LG7dTfN0aNHVVZWpqCgIKf5QUFBys/Pr3SdLl266I033tCQIUN09uxZlZaW6p577tHLL7980f0UFxeruLjY8bmoqMidMgEAqHFr165Vo0aNHJ9jY2O1cuXKKm8vJydHkyZNUrt27SRJbdq0cSx77rnnFBUVpXnz5jnm3XTTTZLOXxJKTk5WWlqaYmNjJUkLFy5URkaGUlJSNGnSJMc6M2fOVN++fR3rzZkzRx9++KGio6MlSa1bt9bWrVu1YMEC9ejRo8rH4q4qDWC1/eJeL8uyKsy7YO/evRo/frz++te/KjMzU+vXr1d2drbi4uIuuv3ExET5+fk5ppCQkKqUWX1sNtcmAJDEYODfhp49eyorK8sxzZ0797K2l5CQoLFjx6pPnz569tlndeDAAceyCz0jlTlw4IDOnTunrl27OuZ5eXnptttu0759+5zaRkVFOf5/7969Onv2rPr27atGjRo5piVLljjt+0pwq2ckICBA9erVq9ALUlBQUKG35ILExER17drVkcw6duyohg0bqnv37po1a5aaN29eYZ0pU6YoISHB8bmoqMh8IAEA4L80bNhQ4eHh1ba96dOna9iwYVq3bp3ef/99TZs2TW+++abuu+8++fj4XHQ96z8PeHGlo6Bhw4aO/y8vL5ckrVu3Ti1atHBqZ7fbL+tY3OVWz0j9+vUVGRmpjIwMp/kZGRnq0qVLpeucPn1aHh7Ou7kwwMe6yBNy7Ha7fH19nSYAAOq6tm3bauLEidq4caMGDRqkxYsXSzr/i/ymTZsqXSc8PFz169fX1q1bHfPOnTunnTt3KiIi4qL7uvHGG2W325WTk6Pw8HCn6Up3ALj9BNaEhAQNHz5cUVFRio6O1muvvaacnBzHZZcpU6bohx9+0JIlSyRJAwYM0COPPKLk5GT169dPeXl5mjBhgm677TYFBwdX79EAAHAVOHnypOOZI5KUnZ2trKwsNWnSRC1btqzQ/syZM5o0aZIeeOABhYWF6dChQ9qxY4fuv/9+See/Wzt06KD4+HjFxcWpfv36+te//qU//OEPCggI0Lhx4zRp0iTH9p977jmdPn1aY8aMuWiNjRs31pNPPqmJEyeqvLxc3bp1U1FRkbZt26ZGjRpp5MiR1X9iLsLtMDJkyBAdO3ZMM2fOVF5entq3b6/09HSFhoZKkvLy8pyeOTJq1CidOHFCr7zyip544gn5+/urV69e+vvf/159RwEAwFVk586d6tmzp+PzhaEHI0eOVFpaWoX29erV07FjxzRixAgdOXJEAQEBGjRokGbMmCHpfI/Jxo0b9fTTT+u2226Tj4+Pbr/9dj344IOSpGeffVbl5eUaPny4Tpw4oaioKG3YsEHXXHPNJev829/+psDAQCUmJurgwYPy9/fXLbfcoqeffrqazoRrbNbFrpVcRYqKiuTn56fCwsJqvWTj8ivGXRxoZpvu+r6taS63dH2jhtTEuytsM1zbqOvnUapL59Kdv7XVfy6v/vMoVf+5dPU8SnXrXNbk3+/QhqGa33W+AloEVPqrcZRbnedRv94ENeLs2bPKzs52PJn9v7n6/c27aQAAgFG8tRcAgKuJO08oj6obPUL0jAAAAKMIIwAAwCjCCAAAMIowAgAwwvrPf7XgpiJcQnXclMsAVgCAEceKj6mkrEQ6J8nLdDU1z9VxqbVtSOrp06clyfGG4aogjAAAjDhVekprvl+jB+s/KH/5nw8k//Vck7Nn3dmaW42vau4dtrnjtixLp0+fVkFBgfz9/R2veqkKwggAwJjF355/98o9ofeofr36sv1XGsk+5c6Wsqu3sBpw9Khr7bLlYkNJyjZ/3P7+/mrWrNllbYMwAgAwxpKl1G9T9Wb2mwrwDnAKI1895s6Wvqr22qpbbKxr7b6Siw0l6Suzx+3l5XVZPSIXEEYA/La5+rzz6TVaxW/e6bLTyjmV4zTvF08W/xVuNTbi++9da+ctFxtK7p6kqxZhBACAOs/VlwyZubWJW3txZdlsrk0AgN8MwggAADCKMAIAAIwijAAAAKMIIwCA6sGYMFQRYQQAABhFGAEAAEYRRgAAgFGEEQAAYBRPYAUAoJayzXBtQLA1rYYLuUz0jAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCNAbeTqq9p5XTuAWoAwAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjqhRG5s2bp7CwMHl7eysyMlJbtmy5ZPvi4mJNnTpVoaGhstvtuv7665WamlqlggEAQN3i6e4KK1as0IQJEzRv3jx17dpVCxYsUGxsrPbu3auWLVtWus7gwYN15MgRpaSkKDw8XAUFBSotLb3s4gEAQO3ndhiZM2eOxowZo7Fjx0qSkpKStGHDBiUnJysxMbFC+/Xr12vz5s06ePCgmjRpIklq1arV5VUNAADqDLcu05SUlCgzM1MxMTFO82NiYrRt27ZK11mzZo2ioqL03HPPqUWLFmrbtq2efPJJnTlz5qL7KS4uVlFRkdMEAADqJrd6Ro4ePaqysjIFBQU5zQ8KClJ+fn6l6xw8eFBbt26Vt7e33n33XR09elTx8fE6fvz4RceNJCYmasaMGe6UBgAAaqkqDWC12WxOny3LqjDvgvLyctlsNr3xxhu67bbb1L9/f82ZM0dpaWkX7R2ZMmWKCgsLHVNubm5VygQAALWAWz0jAQEBqlevXoVekIKCggq9JRc0b95cLVq0kJ+fn2NeRESELMvSoUOH1KZNmwrr2O122e12d0oDAAC1lFs9I/Xr11dkZKQyMjKc5mdkZKhLly6VrtO1a1cdPnxYJ0+edMzbv3+/PDw8dN1111WhZAAAUJe4fZkmISFBixYtUmpqqvbt26eJEycqJydHcXFxks5fYhkxYoSj/bBhw9S0aVP98Y9/1N69e/Xxxx9r0qRJGj16tHx8fKrvSAAAQK3k9q29Q4YM0bFjxzRz5kzl5eWpffv2Sk9PV2hoqCQpLy9POTk5jvaNGjVSRkaGHn/8cUVFRalp06YaPHiwZs2aVX1HAQAAai23w4gkxcfHKz4+vtJlaWlpFea1a9euwqUdAAAAiXfTAAAAwwgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAo6oURubNm6ewsDB5e3srMjJSW7ZscWm9Tz75RJ6enurcuXNVdgsAAOogt8PIihUrNGHCBE2dOlW7du1S9+7dFRsbq5ycnEuuV1hYqBEjRqh3795VLhYAANQ9boeROXPmaMyYMRo7dqwiIiKUlJSkkJAQJScnX3K9P//5zxo2bJiio6OrXCwAAKh73AojJSUlyszMVExMjNP8mJgYbdu27aLrLV68WAcOHNC0adNc2k9xcbGKioqcJgAAUDe5FUaOHj2qsrIyBQUFOc0PCgpSfn5+pet88803euqpp/TGG2/I09PTpf0kJibKz8/PMYWEhLhTJgAAqEWqNIDVZrM5fbYsq8I8SSorK9OwYcM0Y8YMtW3b1uXtT5kyRYWFhY4pNze3KmUCAIBawLWuiv8ICAhQvXr1KvSCFBQUVOgtkaQTJ05o586d2rVrlx577DFJUnl5uSzLkqenpzZu3KhevXpVWM9ut8tut7tTGgAAqKXc6hmpX7++IiMjlZGR4TQ/IyNDXbp0qdDe19dXe/bsUVZWlmOKi4vTDTfcoKysLN1+++2XVz0AAKj13OoZkaSEhAQNHz5cUVFRio6O1muvvaacnBzFxcVJOn+J5YcfftCSJUvk4eGh9u3bO60fGBgob2/vCvMBAMBvk9thZMiQITp27JhmzpypvLw8tW/fXunp6QoNDZUk5eXl/eozRwAAAC5wO4xIUnx8vOLj4ytdlpaWdsl1p0+frunTp1dltwAAoA7i3TQAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMCoKoWRefPmKSwsTN7e3oqMjNSWLVsu2vadd95R3759de2118rX11fR0dHasGFDlQsGAAB1i9thZMWKFZowYYKmTp2qXbt2qXv37oqNjVVOTk6l7T/++GP17dtX6enpyszMVM+ePTVgwADt2rXrsosHAAC1n9thZM6cORozZozGjh2riIgIJSUlKSQkRMnJyZW2T0pK0uTJk3XrrbeqTZs2euaZZ9SmTRu99957l108AACo/dwKIyUlJcrMzFRMTIzT/JiYGG3bts2lbZSXl+vEiRNq0qTJRdsUFxerqKjIaQIAAHWTW2Hk6NGjKisrU1BQkNP8oKAg5efnu7SNF154QadOndLgwYMv2iYxMVF+fn6OKSQkxJ0yAQBALVKlAaw2m83ps2VZFeZVZvny5Zo+fbpWrFihwMDAi7abMmWKCgsLHVNubm5VygQAALWApzuNAwICVK9evQq9IAUFBRV6S35pxYoVGjNmjFauXKk+ffpcsq3dbpfdbnenNAAAUEu51TNSv359RUZGKiMjw2l+RkaGunTpctH1li9frlGjRmnZsmW6++67q1YpAACok9zqGZGkhIQEDR8+XFFRUYqOjtZrr72mnJwcxcXFSTp/ieWHH37QkiVLJJ0PIiNGjNBLL72k3/3ud45eFR8fH/n5+VXjoQAAgNrI7TAyZMgQHTt2TDNnzlReXp7at2+v9PR0hYaGSpLy8vKcnjmyYMEClZaW6tFHH9Wjjz7qmD9y5EilpaVd/hEAAIBaze0wIknx8fGKj4+vdNkvA8ZHH31UlV0AAIDfCN5NAwAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjCKMAAAAowgjAADAKMIIAAAwijACAACMIowAAACjCCMAAMAowggAADCKMAIAAIwijAAAAKMIIwAAwCjCCAAAMIowAgAAjKpSGJk3b57CwsLk7e2tyMhIbdmy5ZLtN2/erMjISHl7e6t169aaP39+lYoFAAB1j9thZMWKFZowYYKmTp2qXbt2qXv37oqNjVVOTk6l7bOzs9W/f391795du3bt0tNPP63x48dr1apVl108AACo/dwOI3PmzNGYMWM0duxYRUREKCkpSSEhIUpOTq60/fz589WyZUslJSUpIiJCY8eO1ejRo/X8889fdvEAAKD283SncUlJiTIzM/XUU085zY+JidG2bdsqXWf79u2KiYlxmtevXz+lpKTo3Llz8vLyqrBOcXGxiouLHZ8LCwslSUVFRe6UW21c3utZN7bp8kbNHHNNqe5z6d6PRN05l24dSbWfy7pzHiX+flcn/n5Xj7r09/vC97ZlWZduaLnhhx9+sCRZn3zyidP82bNnW23btq10nTZt2lizZ892mvfJJ59YkqzDhw9Xus60adMsSUxMTExMTEx1YMrNzb1kvnCrZ+QCm83m9NmyrArzfq19ZfMvmDJlihISEhyfy8vLdfz4cTVt2vSS+zGpqKhIISEhys3Nla+vr+lyajXOZfXhXFYPzmP14VxWn9pwLi3L0okTJxQcHHzJdm6FkYCAANWrV0/5+flO8wsKChQUFFTpOs2aNau0vaenp5o2bVrpOna7XXa73Wmev7+/O6Ua4+vre9X+UNQ2nMvqw7msHpzH6sO5rD5X+7n08/P71TZuDWCtX7++IiMjlZGR4TQ/IyNDXbp0qXSd6OjoCu03btyoqKioSseLAACA3xa376ZJSEjQokWLlJqaqn379mnixInKyclRXFycpPOXWEaMGOFoHxcXp++//14JCQnat2+fUlNTlZKSoieffLL6jgIAANRabo8ZGTJkiI4dO6aZM2cqLy9P7du3V3p6ukJDQyVJeXl5Ts8cCQsLU3p6uiZOnKhXX31VwcHBmjt3ru6///7qO4qrgN1u17Rp0ypcXoL7OJfVh3NZPTiP1YdzWX3q0rm0Wdav3W8DAABQc3g3DQAAMIowAgAAjCKMAAAAowgjAADAKMIIUIcxPh1AbVClx8ED1enQoUNKTk7Wtm3blJ+fL5vNpqCgIHXp0kVxcXEKCQkxXWKtZbfbtXv3bkVERJguBQAuilt7q8FPP/2k119/Xd98842aN2+ukSNH8gXqoq1btyo2NlYhISGKiYlRUFCQLMtSQUGBMjIylJubq/fff19du3Y1XepV7b/f5fTfXnrpJT388MOOVy/MmTPnSpZVa505c0aZmZlq0qSJbrzxRqdlZ8+e1VtvveX0cEdUTW5urqZNm6bU1FTTpdQK+/bt06effqro6Gi1a9dOX331lV566SUVFxfr4YcfVq9evUyXWGWEkSoIDg7Wnj171LRpU2VnZzsehd+hQwft27dPJ06c0Keffqp27doZrvTqd+utt6pbt2568cUXK10+ceJEbd26VTt27LjCldUuHh4e6tSpU4V3OG3evFlRUVFq2LChbDabPvzwQzMF1iL79+9XTEyMcnJyZLPZ1L17dy1fvlzNmzeXJB05ckTBwcEqKyszXGntt3v3bt1yyy2cSxesX79e9957rxo1aqTTp0/r3Xff1YgRI9SpUydZlqXNmzdrw4YNtTaQEEaqwMPDQ/n5+QoMDNSDDz6o/Px8rVu3Tg0aNFBxcbEeeOABeXt7a+XKlaZLver5+PgoKytLN9xwQ6XLv/rqK9188806c+bMFa6sdklMTNTChQu1aNEip3+MvLy8tHv37gq/3ePi7rvvPpWWlmrx4sX6+eeflZCQoP/7v//TRx99pJYtWxJG3LBmzZpLLj948KCeeOIJzqULunTpol69emnWrFl68803FR8fr3Hjxmn27NmSpKlTp2rHjh3auHGj4UqryILbbDabdeTIEcuyLCssLMzatGmT0/JPP/3Uuu6660yUVuuEhYVZqampF12emppqhYWFXcGKaq/PP//catu2rfXEE09YJSUllmVZlqenp/Xll18arqx2CQwMtP797387zYuPj7datmxpHThwwMrPz7c8PDwMVVe72Gw2y8PDw7LZbBedOJeu8fX1tb755hvLsiyrrKzM8vT0tDIzMx3L9+zZYwUFBZkq77IxgLWKbDabJKm4uFhBQUFOy4KCgvTjjz+aKKvWefLJJxUXF6fMzEz17dtXQUFBstlsys/PV0ZGhhYtWqSkpCTTZdYKt956qzIzM/Xoo48qKipK//znPx0/p3DdmTNn5Onp/E/jq6++Kg8PD/Xo0UPLli0zVFnt07x5c7366qsaOHBgpcuzsrIUGRl5ZYuqAzw8POTt7e10WbZx48YqLCw0V9RlIoxUUe/eveXp6amioiLt379fN910k2NZTk6OAgICDFZXe8THx6tp06Z68cUXtWDBAkd3bb169RQZGaklS5Zo8ODBhqusPRo1aqTXX39db775pvr27Uv3dxW0a9dOO3furHAH0ssvvyzLsnTPPfcYqqz2iYyM1BdffHHRMGKz2bj93EWtWrXSt99+q/DwcEnS9u3b1bJlS8fy3Nxcx7im2ogwUgXTpk1z+tygQQOnz++99566d+9+JUuq1YYMGaIhQ4bo3LlzOnr0qCQpICBAXl5ehiurvYYOHapu3bopMzPT8UZtuOa+++7T8uXLNXz48ArLXnnlFZWXl2v+/PkGKqt9Jk2apFOnTl10eXh4uP71r39dwYpqr3Hjxjn9ctG+fXun5e+//36tHbwqMYAVAAAYxhNYAQCAUYQRAABgFGEEAAAYRRgBAABGEUYAAIBRhBEAAGAUYQQAABhFGAEAAEb9P+eeYxANGNS0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Models.sort_values(by = \"F1 score\", ascending = False).plot(kind = \"bar\", color = [\"blue\", 'red','green','yellow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "3efce02e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the lightgbm model\n",
    "import lightgbm as lgb\n",
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2816c58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "afd2ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the results\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "62aa1854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Recall: 76.98\n",
      "Negative Recall: 95.07\n",
      "Positive Precision: 92.84\n",
      "Negative Precision: 83.27\n",
      "Positive F1-score: 84.17\n",
      "Negative F1-score: 88.78\n"
     ]
    }
   ],
   "source": [
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "negative_recall = recall_score(y_test, y_pred, pos_label=0)\n",
    "\n",
    "print(\"Positive Recall: {:.2f}\".format(positive_recall*100))\n",
    "print(\"Negative Recall: {:.2f}\".format(negative_recall*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "negative_precision = precision_score(y_test, y_pred, pos_label=0)\n",
    "\n",
    "print(\"Positive Precision: {:.2f}\".format(positive_precision*100))\n",
    "print(\"Negative Precision: {:.2f}\".format(negative_precision*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "negative_f1 = f1_score(y_test, y_pred, pos_label=0)\n",
    "\n",
    "print(\"Positive F1-score: {:.2f}\".format(positive_f1*100))\n",
    "print(\"Negative F1-score: {:.2f}\".format(negative_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "db3b668c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model accuracy score: 0.8687\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# view accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_pred, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "324849a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[463  24]\n",
      " [ 93 311]]\n",
      "\n",
      "True Positives(TP) =  463\n",
      "\n",
      "True Negatives(TN) =  311\n",
      "\n",
      "False Positives(FP) =  24\n",
      "\n",
      "False Negatives(FN) =  93\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# view confusion-matrix\n",
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "f8623d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.95      0.89       487\n",
      "         1.0       0.93      0.77      0.84       404\n",
      "\n",
      "    accuracy                           0.87       891\n",
      "   macro avg       0.88      0.86      0.86       891\n",
      "weighted avg       0.88      0.87      0.87       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "ca413047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8416779431664412"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c8ec4f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8686868686868687"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99f361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65755e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae6f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ac88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "90a7798d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "cc2aa4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('xgb', gsXGoost))\n",
    "models.append(('rfc', random_forest))\n",
    "models.append(('lgb', clf))\n",
    "\n",
    "# Create an ensemble model using the VotingClassifier\n",
    "ensemble = VotingClassifier(models, voting='soft')\n",
    "\n",
    "# Train the ensemble model on the training data\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data using the ensemble model\n",
    "y_pred = ensemble.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "dc0b3969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0.\n",
      " 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0.\n",
      " 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0.\n",
      " 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1.\n",
      " 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 1.\n",
      " 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "6ae4e346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.14870194 0.85129806]\n",
      " [0.91836975 0.08163025]\n",
      " [0.52222397 0.47777603]\n",
      " ...\n",
      " [0.77494918 0.22505083]\n",
      " [0.73839926 0.26160073]\n",
      " [0.81017139 0.18982861]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = ensemble.predict_proba(X_test)\n",
    "print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "4447640e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble accuracy: 89.67\n",
      "Ensemble f1 score: 87.53\n",
      "Ensemble precision: 96.71\n",
      "Ensemble recall: 79.95\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the ensemble model's accuracy, f1 score, precision, and recall\n",
    "ensemble_accuracy = accuracy_score(y_test, y_pred)\n",
    "ensemble_f1_score = f1_score(y_test, y_pred)\n",
    "ensemble_precision = precision_score(y_test, y_pred)\n",
    "ensemble_recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Ensemble accuracy:\", round(ensemble_accuracy*100,2))\n",
    "print(\"Ensemble f1 score:\", round(ensemble_f1_score*100,2))\n",
    "print(\"Ensemble precision:\", round(ensemble_precision*100,2))\n",
    "print(\"Ensemble recall:\", round(ensemble_recall*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d0839",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f03857fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Recall: 79.95\n",
      "Negative Recall: 97.74\n",
      "Positive Precision: 96.71\n",
      "Negative Precision: 85.46\n",
      "Positive F1-score: 87.53\n",
      "Negative F1-score: 91.19\n"
     ]
    }
   ],
   "source": [
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "negative_recall = recall_score(y_test, y_pred, pos_label=0)\n",
    "\n",
    "print(\"Positive Recall: {:.2f}\".format(positive_recall*100))\n",
    "print(\"Negative Recall: {:.2f}\".format(negative_recall*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "negative_precision = precision_score(y_test, y_pred, pos_label=0)\n",
    "\n",
    "print(\"Positive Precision: {:.2f}\".format(positive_precision*100))\n",
    "print(\"Negative Precision: {:.2f}\".format(negative_precision*100))\n",
    "\n",
    "\n",
    "# assuming y_true and y_pred are arrays of true and predicted labels, respectively\n",
    "positive_f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "negative_f1 = f1_score(y_test, y_pred, pos_label=0)\n",
    "\n",
    "print(\"Positive F1-score: {:.2f}\".format(positive_f1*100))\n",
    "print(\"Negative F1-score: {:.2f}\".format(negative_f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100c7e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "a663e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "313aae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "daba0ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ensemble, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fc32a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
