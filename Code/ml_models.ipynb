{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d2ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn import metrics\n",
    "import scikitplot as skplt\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4755d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2093</th>\n",
       "      <th>2094</th>\n",
       "      <th>2095</th>\n",
       "      <th>2096</th>\n",
       "      <th>2097</th>\n",
       "      <th>2098</th>\n",
       "      <th>2099</th>\n",
       "      <th>2100</th>\n",
       "      <th>2101</th>\n",
       "      <th>2102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.512804</td>\n",
       "      <td>0.058938</td>\n",
       "      <td>0.529435</td>\n",
       "      <td>0.070050</td>\n",
       "      <td>0.265008</td>\n",
       "      <td>0.027912</td>\n",
       "      <td>0.885629</td>\n",
       "      <td>0.316553</td>\n",
       "      <td>0.150481</td>\n",
       "      <td>0.259909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967715</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.037648</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.037648</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.543392</td>\n",
       "      <td>0.072460</td>\n",
       "      <td>0.357297</td>\n",
       "      <td>1.824225</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.305774</td>\n",
       "      <td>0.442124</td>\n",
       "      <td>0.238234</td>\n",
       "      <td>0.404805</td>\n",
       "      <td>0.222462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973693</td>\n",
       "      <td>0.038753</td>\n",
       "      <td>0.040148</td>\n",
       "      <td>0.040421</td>\n",
       "      <td>0.038398</td>\n",
       "      <td>0.038753</td>\n",
       "      <td>0.040148</td>\n",
       "      <td>0.040421</td>\n",
       "      <td>0.038398</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.462972</td>\n",
       "      <td>0.023815</td>\n",
       "      <td>0.995784</td>\n",
       "      <td>0.411113</td>\n",
       "      <td>0.291706</td>\n",
       "      <td>0.221538</td>\n",
       "      <td>0.647339</td>\n",
       "      <td>0.891442</td>\n",
       "      <td>0.081914</td>\n",
       "      <td>0.127952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964691</td>\n",
       "      <td>0.043936</td>\n",
       "      <td>0.040705</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.043020</td>\n",
       "      <td>0.043936</td>\n",
       "      <td>0.040705</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.043020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.614602</td>\n",
       "      <td>0.134259</td>\n",
       "      <td>0.112894</td>\n",
       "      <td>0.660946</td>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.710268</td>\n",
       "      <td>0.784855</td>\n",
       "      <td>0.113133</td>\n",
       "      <td>0.261060</td>\n",
       "      <td>0.327604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982214</td>\n",
       "      <td>0.032544</td>\n",
       "      <td>0.031366</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>0.032544</td>\n",
       "      <td>0.031366</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.749940</td>\n",
       "      <td>0.061687</td>\n",
       "      <td>0.795646</td>\n",
       "      <td>0.744609</td>\n",
       "      <td>0.168979</td>\n",
       "      <td>0.680204</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>0.259196</td>\n",
       "      <td>0.411569</td>\n",
       "      <td>0.161880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997227</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>0.021543</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>0.021543</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.021696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815</th>\n",
       "      <td>0.649234</td>\n",
       "      <td>0.032202</td>\n",
       "      <td>0.160830</td>\n",
       "      <td>1.542416</td>\n",
       "      <td>0.286979</td>\n",
       "      <td>0.173201</td>\n",
       "      <td>0.634189</td>\n",
       "      <td>0.147836</td>\n",
       "      <td>0.376638</td>\n",
       "      <td>0.165056</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995145</td>\n",
       "      <td>0.028403</td>\n",
       "      <td>0.027558</td>\n",
       "      <td>0.027746</td>\n",
       "      <td>0.027644</td>\n",
       "      <td>0.028403</td>\n",
       "      <td>0.027558</td>\n",
       "      <td>0.027746</td>\n",
       "      <td>0.027644</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7816</th>\n",
       "      <td>0.198588</td>\n",
       "      <td>0.189913</td>\n",
       "      <td>0.593163</td>\n",
       "      <td>2.020908</td>\n",
       "      <td>0.071868</td>\n",
       "      <td>0.717029</td>\n",
       "      <td>0.311775</td>\n",
       "      <td>0.261614</td>\n",
       "      <td>0.335414</td>\n",
       "      <td>0.229683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977090</td>\n",
       "      <td>0.039669</td>\n",
       "      <td>0.040739</td>\n",
       "      <td>0.041195</td>\n",
       "      <td>0.039638</td>\n",
       "      <td>0.039669</td>\n",
       "      <td>0.040739</td>\n",
       "      <td>0.041195</td>\n",
       "      <td>0.039638</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7817</th>\n",
       "      <td>0.335369</td>\n",
       "      <td>0.144272</td>\n",
       "      <td>0.238421</td>\n",
       "      <td>1.303674</td>\n",
       "      <td>0.579740</td>\n",
       "      <td>0.189792</td>\n",
       "      <td>0.779709</td>\n",
       "      <td>0.755286</td>\n",
       "      <td>0.638449</td>\n",
       "      <td>0.240480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960393</td>\n",
       "      <td>0.054801</td>\n",
       "      <td>0.057350</td>\n",
       "      <td>0.058956</td>\n",
       "      <td>0.054631</td>\n",
       "      <td>0.054801</td>\n",
       "      <td>0.057350</td>\n",
       "      <td>0.058956</td>\n",
       "      <td>0.054631</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7818</th>\n",
       "      <td>0.504851</td>\n",
       "      <td>0.039228</td>\n",
       "      <td>0.283918</td>\n",
       "      <td>0.772767</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>0.284417</td>\n",
       "      <td>0.383878</td>\n",
       "      <td>0.030593</td>\n",
       "      <td>0.200283</td>\n",
       "      <td>0.213998</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957405</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.068377</td>\n",
       "      <td>0.067482</td>\n",
       "      <td>0.065991</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>0.068377</td>\n",
       "      <td>0.067482</td>\n",
       "      <td>0.065991</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7819</th>\n",
       "      <td>0.172708</td>\n",
       "      <td>0.366924</td>\n",
       "      <td>0.370203</td>\n",
       "      <td>2.723996</td>\n",
       "      <td>1.026903</td>\n",
       "      <td>0.141809</td>\n",
       "      <td>0.553321</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>0.576845</td>\n",
       "      <td>0.100579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.961967</td>\n",
       "      <td>0.057902</td>\n",
       "      <td>0.055640</td>\n",
       "      <td>0.058397</td>\n",
       "      <td>0.059050</td>\n",
       "      <td>0.057902</td>\n",
       "      <td>0.055640</td>\n",
       "      <td>0.058397</td>\n",
       "      <td>0.059050</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7820 rows × 2103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.512804  0.058938  0.529435  0.070050  0.265008  0.027912  0.885629   \n",
       "1     0.543392  0.072460  0.357297  1.824225  0.011772  0.305774  0.442124   \n",
       "2     0.462972  0.023815  0.995784  0.411113  0.291706  0.221538  0.647339   \n",
       "3     0.614602  0.134259  0.112894  0.660946  0.099556  0.710268  0.784855   \n",
       "4     0.749940  0.061687  0.795646  0.744609  0.168979  0.680204  0.395964   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "7815  0.649234  0.032202  0.160830  1.542416  0.286979  0.173201  0.634189   \n",
       "7816  0.198588  0.189913  0.593163  2.020908  0.071868  0.717029  0.311775   \n",
       "7817  0.335369  0.144272  0.238421  1.303674  0.579740  0.189792  0.779709   \n",
       "7818  0.504851  0.039228  0.283918  0.772767  0.015357  0.284417  0.383878   \n",
       "7819  0.172708  0.366924  0.370203  2.723996  1.026903  0.141809  0.553321   \n",
       "\n",
       "             7         8         9  ...      2093      2094      2095  \\\n",
       "0     0.316553  0.150481  0.259909  ...  0.967715  0.038204  0.036946   \n",
       "1     0.238234  0.404805  0.222462  ...  0.973693  0.038753  0.040148   \n",
       "2     0.891442  0.081914  0.127952  ...  0.964691  0.043936  0.040705   \n",
       "3     0.113133  0.261060  0.327604  ...  0.982214  0.032544  0.031366   \n",
       "4     0.259196  0.411569  0.161880  ...  0.997227  0.021783  0.021543   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "7815  0.147836  0.376638  0.165056  ...  0.995145  0.028403  0.027558   \n",
       "7816  0.261614  0.335414  0.229683  ...  0.977090  0.039669  0.040739   \n",
       "7817  0.755286  0.638449  0.240480  ...  0.960393  0.054801  0.057350   \n",
       "7818  0.030593  0.200283  0.213998  ...  0.957405  0.068200  0.068377   \n",
       "7819  0.439500  0.576845  0.100579  ...  0.961967  0.057902  0.055640   \n",
       "\n",
       "          2096      2097      2098      2099      2100      2101  2102  \n",
       "0     0.037648  0.037300  0.038204  0.036946  0.037648  0.037300   1.0  \n",
       "1     0.040421  0.038398  0.038753  0.040148  0.040421  0.038398   1.0  \n",
       "2     0.041327  0.043020  0.043936  0.040705  0.041327  0.043020   1.0  \n",
       "3     0.032945  0.032998  0.032544  0.031366  0.032945  0.032998   1.0  \n",
       "4     0.021990  0.021696  0.021783  0.021543  0.021990  0.021696   1.0  \n",
       "...        ...       ...       ...       ...       ...       ...   ...  \n",
       "7815  0.027746  0.027644  0.028403  0.027558  0.027746  0.027644   1.0  \n",
       "7816  0.041195  0.039638  0.039669  0.040739  0.041195  0.039638   1.0  \n",
       "7817  0.058956  0.054631  0.054801  0.057350  0.058956  0.054631   1.0  \n",
       "7818  0.067482  0.065991  0.068200  0.068377  0.067482  0.065991   1.0  \n",
       "7819  0.058397  0.059050  0.057902  0.055640  0.058397  0.059050   1.0  \n",
       "\n",
       "[7820 rows x 2103 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample1 = pd.read_csv(\"Breast_Cancer_Augmented_Positive_Dataset_8k.csv\")\n",
    "df_sample1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac0beaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2093</th>\n",
       "      <th>2094</th>\n",
       "      <th>2095</th>\n",
       "      <th>2096</th>\n",
       "      <th>2097</th>\n",
       "      <th>2098</th>\n",
       "      <th>2099</th>\n",
       "      <th>2100</th>\n",
       "      <th>2101</th>\n",
       "      <th>2102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185713</td>\n",
       "      <td>0.129328</td>\n",
       "      <td>0.151128</td>\n",
       "      <td>1.148885</td>\n",
       "      <td>0.355841</td>\n",
       "      <td>0.092020</td>\n",
       "      <td>0.641751</td>\n",
       "      <td>0.588707</td>\n",
       "      <td>0.371998</td>\n",
       "      <td>0.493291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956743</td>\n",
       "      <td>0.050902</td>\n",
       "      <td>0.053116</td>\n",
       "      <td>0.054807</td>\n",
       "      <td>0.050988</td>\n",
       "      <td>0.050902</td>\n",
       "      <td>0.053116</td>\n",
       "      <td>0.054807</td>\n",
       "      <td>0.050988</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.360726</td>\n",
       "      <td>0.373147</td>\n",
       "      <td>0.526488</td>\n",
       "      <td>0.537230</td>\n",
       "      <td>0.136993</td>\n",
       "      <td>0.089766</td>\n",
       "      <td>0.505770</td>\n",
       "      <td>0.140908</td>\n",
       "      <td>0.120453</td>\n",
       "      <td>0.137948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.025075</td>\n",
       "      <td>0.023461</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>0.023263</td>\n",
       "      <td>0.025075</td>\n",
       "      <td>0.023461</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>0.023263</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.157023</td>\n",
       "      <td>0.167137</td>\n",
       "      <td>0.237207</td>\n",
       "      <td>1.282194</td>\n",
       "      <td>0.121771</td>\n",
       "      <td>0.533974</td>\n",
       "      <td>0.293243</td>\n",
       "      <td>0.182768</td>\n",
       "      <td>0.672679</td>\n",
       "      <td>0.248403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973035</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.034887</td>\n",
       "      <td>0.035874</td>\n",
       "      <td>0.034150</td>\n",
       "      <td>0.033974</td>\n",
       "      <td>0.034887</td>\n",
       "      <td>0.035874</td>\n",
       "      <td>0.034150</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166641</td>\n",
       "      <td>0.767016</td>\n",
       "      <td>0.655124</td>\n",
       "      <td>1.818139</td>\n",
       "      <td>0.512169</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>0.748262</td>\n",
       "      <td>0.146314</td>\n",
       "      <td>0.671473</td>\n",
       "      <td>0.196390</td>\n",
       "      <td>...</td>\n",
       "      <td>0.985751</td>\n",
       "      <td>0.030838</td>\n",
       "      <td>0.029879</td>\n",
       "      <td>0.031978</td>\n",
       "      <td>0.031594</td>\n",
       "      <td>0.030838</td>\n",
       "      <td>0.029879</td>\n",
       "      <td>0.031978</td>\n",
       "      <td>0.031594</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.111832</td>\n",
       "      <td>0.024164</td>\n",
       "      <td>0.259883</td>\n",
       "      <td>1.798461</td>\n",
       "      <td>0.196784</td>\n",
       "      <td>0.589911</td>\n",
       "      <td>0.254228</td>\n",
       "      <td>0.505094</td>\n",
       "      <td>0.795052</td>\n",
       "      <td>0.341958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995997</td>\n",
       "      <td>0.015538</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>0.015983</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.015538</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>0.015983</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.215518</td>\n",
       "      <td>0.023180</td>\n",
       "      <td>0.034412</td>\n",
       "      <td>1.870273</td>\n",
       "      <td>1.148400</td>\n",
       "      <td>0.741835</td>\n",
       "      <td>0.962309</td>\n",
       "      <td>0.432459</td>\n",
       "      <td>0.227685</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976251</td>\n",
       "      <td>0.040627</td>\n",
       "      <td>0.041627</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.039499</td>\n",
       "      <td>0.040627</td>\n",
       "      <td>0.041627</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.039499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.744583</td>\n",
       "      <td>0.083952</td>\n",
       "      <td>0.237501</td>\n",
       "      <td>1.808680</td>\n",
       "      <td>0.223173</td>\n",
       "      <td>0.336731</td>\n",
       "      <td>0.729377</td>\n",
       "      <td>0.256534</td>\n",
       "      <td>0.373716</td>\n",
       "      <td>0.150315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966343</td>\n",
       "      <td>0.039391</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.036356</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.039391</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.036356</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.200996</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.161329</td>\n",
       "      <td>0.846234</td>\n",
       "      <td>0.154310</td>\n",
       "      <td>0.213440</td>\n",
       "      <td>0.589500</td>\n",
       "      <td>0.088370</td>\n",
       "      <td>0.261969</td>\n",
       "      <td>0.466251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959386</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.047710</td>\n",
       "      <td>0.051098</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.047710</td>\n",
       "      <td>0.051098</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.402526</td>\n",
       "      <td>1.326257</td>\n",
       "      <td>0.970394</td>\n",
       "      <td>1.177871</td>\n",
       "      <td>0.442189</td>\n",
       "      <td>0.288784</td>\n",
       "      <td>0.841492</td>\n",
       "      <td>0.825971</td>\n",
       "      <td>0.238176</td>\n",
       "      <td>0.207474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984141</td>\n",
       "      <td>0.025219</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.024976</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.025219</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.024976</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.771130</td>\n",
       "      <td>0.122112</td>\n",
       "      <td>0.172120</td>\n",
       "      <td>2.294095</td>\n",
       "      <td>0.164705</td>\n",
       "      <td>0.061384</td>\n",
       "      <td>0.619167</td>\n",
       "      <td>0.497287</td>\n",
       "      <td>0.422912</td>\n",
       "      <td>0.131336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964358</td>\n",
       "      <td>0.044209</td>\n",
       "      <td>0.044828</td>\n",
       "      <td>0.046743</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>0.044209</td>\n",
       "      <td>0.044828</td>\n",
       "      <td>0.046743</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.185713  0.129328  0.151128  1.148885  0.355841  0.092020  0.641751   \n",
       "1     0.360726  0.373147  0.526488  0.537230  0.136993  0.089766  0.505770   \n",
       "2     0.157023  0.167137  0.237207  1.282194  0.121771  0.533974  0.293243   \n",
       "3     0.166641  0.767016  0.655124  1.818139  0.512169  0.010876  0.748262   \n",
       "4     0.111832  0.024164  0.259883  1.798461  0.196784  0.589911  0.254228   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.215518  0.023180  0.034412  1.870273  1.148400  0.741835  0.962309   \n",
       "9996  0.744583  0.083952  0.237501  1.808680  0.223173  0.336731  0.729377   \n",
       "9997  1.200996  0.011994  0.161329  0.846234  0.154310  0.213440  0.589500   \n",
       "9998  0.402526  1.326257  0.970394  1.177871  0.442189  0.288784  0.841492   \n",
       "9999  0.771130  0.122112  0.172120  2.294095  0.164705  0.061384  0.619167   \n",
       "\n",
       "             7         8         9  ...      2093      2094      2095  \\\n",
       "0     0.588707  0.371998  0.493291  ...  0.956743  0.050902  0.053116   \n",
       "1     0.140908  0.120453  0.137948  ...  0.995146  0.025075  0.023461   \n",
       "2     0.182768  0.672679  0.248403  ...  0.973035  0.033974  0.034887   \n",
       "3     0.146314  0.671473  0.196390  ...  0.985751  0.030838  0.029879   \n",
       "4     0.505094  0.795052  0.341958  ...  0.995997  0.015538  0.015425   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  0.432459  0.227685  0.058556  ...  0.976251  0.040627  0.041627   \n",
       "9996  0.256534  0.373716  0.150315  ...  0.966343  0.039391  0.037296   \n",
       "9997  0.088370  0.261969  0.466251  ...  0.959386  0.047217  0.047710   \n",
       "9998  0.825971  0.238176  0.207474  ...  0.984141  0.025219  0.024221   \n",
       "9999  0.497287  0.422912  0.131336  ...  0.964358  0.044209  0.044828   \n",
       "\n",
       "          2096      2097      2098      2099      2100      2101  2102  \n",
       "0     0.054807  0.050988  0.050902  0.053116  0.054807  0.050988   0.0  \n",
       "1     0.021841  0.023263  0.025075  0.023461  0.021841  0.023263   0.0  \n",
       "2     0.035874  0.034150  0.033974  0.034887  0.035874  0.034150   0.0  \n",
       "3     0.031978  0.031594  0.030838  0.029879  0.031978  0.031594   0.0  \n",
       "4     0.015983  0.015564  0.015538  0.015425  0.015983  0.015564   0.0  \n",
       "...        ...       ...       ...       ...       ...       ...   ...  \n",
       "9995  0.041772  0.039499  0.040627  0.041627  0.041772  0.039499   0.0  \n",
       "9996  0.036356  0.037387  0.039391  0.037296  0.036356  0.037387   0.0  \n",
       "9997  0.051098  0.049133  0.047217  0.047710  0.051098  0.049133   0.0  \n",
       "9998  0.024976  0.025639  0.025219  0.024221  0.024976  0.025639   0.0  \n",
       "9999  0.046743  0.044648  0.044209  0.044828  0.046743  0.044648   0.0  \n",
       "\n",
       "[10000 rows x 2103 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample2 = pd.read_csv(\"Breast_Cancer_10k_2_Dataset.csv\")\n",
    "df_sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d5d1801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2093</th>\n",
       "      <th>2094</th>\n",
       "      <th>2095</th>\n",
       "      <th>2096</th>\n",
       "      <th>2097</th>\n",
       "      <th>2098</th>\n",
       "      <th>2099</th>\n",
       "      <th>2100</th>\n",
       "      <th>2101</th>\n",
       "      <th>2102</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.512804</td>\n",
       "      <td>0.058938</td>\n",
       "      <td>0.529435</td>\n",
       "      <td>0.070050</td>\n",
       "      <td>0.265008</td>\n",
       "      <td>0.027912</td>\n",
       "      <td>0.885629</td>\n",
       "      <td>0.316553</td>\n",
       "      <td>0.150481</td>\n",
       "      <td>0.259909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967715</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.037648</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.038204</td>\n",
       "      <td>0.036946</td>\n",
       "      <td>0.037648</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.543392</td>\n",
       "      <td>0.072460</td>\n",
       "      <td>0.357297</td>\n",
       "      <td>1.824225</td>\n",
       "      <td>0.011772</td>\n",
       "      <td>0.305774</td>\n",
       "      <td>0.442124</td>\n",
       "      <td>0.238234</td>\n",
       "      <td>0.404805</td>\n",
       "      <td>0.222462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973693</td>\n",
       "      <td>0.038753</td>\n",
       "      <td>0.040148</td>\n",
       "      <td>0.040421</td>\n",
       "      <td>0.038398</td>\n",
       "      <td>0.038753</td>\n",
       "      <td>0.040148</td>\n",
       "      <td>0.040421</td>\n",
       "      <td>0.038398</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.462972</td>\n",
       "      <td>0.023815</td>\n",
       "      <td>0.995784</td>\n",
       "      <td>0.411113</td>\n",
       "      <td>0.291706</td>\n",
       "      <td>0.221538</td>\n",
       "      <td>0.647339</td>\n",
       "      <td>0.891442</td>\n",
       "      <td>0.081914</td>\n",
       "      <td>0.127952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964691</td>\n",
       "      <td>0.043936</td>\n",
       "      <td>0.040705</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.043020</td>\n",
       "      <td>0.043936</td>\n",
       "      <td>0.040705</td>\n",
       "      <td>0.041327</td>\n",
       "      <td>0.043020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.614602</td>\n",
       "      <td>0.134259</td>\n",
       "      <td>0.112894</td>\n",
       "      <td>0.660946</td>\n",
       "      <td>0.099556</td>\n",
       "      <td>0.710268</td>\n",
       "      <td>0.784855</td>\n",
       "      <td>0.113133</td>\n",
       "      <td>0.261060</td>\n",
       "      <td>0.327604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.982214</td>\n",
       "      <td>0.032544</td>\n",
       "      <td>0.031366</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>0.032544</td>\n",
       "      <td>0.031366</td>\n",
       "      <td>0.032945</td>\n",
       "      <td>0.032998</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.749940</td>\n",
       "      <td>0.061687</td>\n",
       "      <td>0.795646</td>\n",
       "      <td>0.744609</td>\n",
       "      <td>0.168979</td>\n",
       "      <td>0.680204</td>\n",
       "      <td>0.395964</td>\n",
       "      <td>0.259196</td>\n",
       "      <td>0.411569</td>\n",
       "      <td>0.161880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997227</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>0.021543</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.021783</td>\n",
       "      <td>0.021543</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.021696</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.215518</td>\n",
       "      <td>0.023180</td>\n",
       "      <td>0.034412</td>\n",
       "      <td>1.870273</td>\n",
       "      <td>1.148400</td>\n",
       "      <td>0.741835</td>\n",
       "      <td>0.962309</td>\n",
       "      <td>0.432459</td>\n",
       "      <td>0.227685</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976251</td>\n",
       "      <td>0.040627</td>\n",
       "      <td>0.041627</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.039499</td>\n",
       "      <td>0.040627</td>\n",
       "      <td>0.041627</td>\n",
       "      <td>0.041772</td>\n",
       "      <td>0.039499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.744583</td>\n",
       "      <td>0.083952</td>\n",
       "      <td>0.237501</td>\n",
       "      <td>1.808680</td>\n",
       "      <td>0.223173</td>\n",
       "      <td>0.336731</td>\n",
       "      <td>0.729377</td>\n",
       "      <td>0.256534</td>\n",
       "      <td>0.373716</td>\n",
       "      <td>0.150315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966343</td>\n",
       "      <td>0.039391</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.036356</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.039391</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.036356</td>\n",
       "      <td>0.037387</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.200996</td>\n",
       "      <td>0.011994</td>\n",
       "      <td>0.161329</td>\n",
       "      <td>0.846234</td>\n",
       "      <td>0.154310</td>\n",
       "      <td>0.213440</td>\n",
       "      <td>0.589500</td>\n",
       "      <td>0.088370</td>\n",
       "      <td>0.261969</td>\n",
       "      <td>0.466251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959386</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.047710</td>\n",
       "      <td>0.051098</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.047710</td>\n",
       "      <td>0.051098</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.402526</td>\n",
       "      <td>1.326257</td>\n",
       "      <td>0.970394</td>\n",
       "      <td>1.177871</td>\n",
       "      <td>0.442189</td>\n",
       "      <td>0.288784</td>\n",
       "      <td>0.841492</td>\n",
       "      <td>0.825971</td>\n",
       "      <td>0.238176</td>\n",
       "      <td>0.207474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.984141</td>\n",
       "      <td>0.025219</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.024976</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.025219</td>\n",
       "      <td>0.024221</td>\n",
       "      <td>0.024976</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.771130</td>\n",
       "      <td>0.122112</td>\n",
       "      <td>0.172120</td>\n",
       "      <td>2.294095</td>\n",
       "      <td>0.164705</td>\n",
       "      <td>0.061384</td>\n",
       "      <td>0.619167</td>\n",
       "      <td>0.497287</td>\n",
       "      <td>0.422912</td>\n",
       "      <td>0.131336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964358</td>\n",
       "      <td>0.044209</td>\n",
       "      <td>0.044828</td>\n",
       "      <td>0.046743</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>0.044209</td>\n",
       "      <td>0.044828</td>\n",
       "      <td>0.046743</td>\n",
       "      <td>0.044648</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17820 rows × 2103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.512804  0.058938  0.529435  0.070050  0.265008  0.027912  0.885629   \n",
       "1     0.543392  0.072460  0.357297  1.824225  0.011772  0.305774  0.442124   \n",
       "2     0.462972  0.023815  0.995784  0.411113  0.291706  0.221538  0.647339   \n",
       "3     0.614602  0.134259  0.112894  0.660946  0.099556  0.710268  0.784855   \n",
       "4     0.749940  0.061687  0.795646  0.744609  0.168979  0.680204  0.395964   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "9995  0.215518  0.023180  0.034412  1.870273  1.148400  0.741835  0.962309   \n",
       "9996  0.744583  0.083952  0.237501  1.808680  0.223173  0.336731  0.729377   \n",
       "9997  1.200996  0.011994  0.161329  0.846234  0.154310  0.213440  0.589500   \n",
       "9998  0.402526  1.326257  0.970394  1.177871  0.442189  0.288784  0.841492   \n",
       "9999  0.771130  0.122112  0.172120  2.294095  0.164705  0.061384  0.619167   \n",
       "\n",
       "             7         8         9  ...      2093      2094      2095  \\\n",
       "0     0.316553  0.150481  0.259909  ...  0.967715  0.038204  0.036946   \n",
       "1     0.238234  0.404805  0.222462  ...  0.973693  0.038753  0.040148   \n",
       "2     0.891442  0.081914  0.127952  ...  0.964691  0.043936  0.040705   \n",
       "3     0.113133  0.261060  0.327604  ...  0.982214  0.032544  0.031366   \n",
       "4     0.259196  0.411569  0.161880  ...  0.997227  0.021783  0.021543   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9995  0.432459  0.227685  0.058556  ...  0.976251  0.040627  0.041627   \n",
       "9996  0.256534  0.373716  0.150315  ...  0.966343  0.039391  0.037296   \n",
       "9997  0.088370  0.261969  0.466251  ...  0.959386  0.047217  0.047710   \n",
       "9998  0.825971  0.238176  0.207474  ...  0.984141  0.025219  0.024221   \n",
       "9999  0.497287  0.422912  0.131336  ...  0.964358  0.044209  0.044828   \n",
       "\n",
       "          2096      2097      2098      2099      2100      2101  2102  \n",
       "0     0.037648  0.037300  0.038204  0.036946  0.037648  0.037300   1.0  \n",
       "1     0.040421  0.038398  0.038753  0.040148  0.040421  0.038398   1.0  \n",
       "2     0.041327  0.043020  0.043936  0.040705  0.041327  0.043020   1.0  \n",
       "3     0.032945  0.032998  0.032544  0.031366  0.032945  0.032998   1.0  \n",
       "4     0.021990  0.021696  0.021783  0.021543  0.021990  0.021696   1.0  \n",
       "...        ...       ...       ...       ...       ...       ...   ...  \n",
       "9995  0.041772  0.039499  0.040627  0.041627  0.041772  0.039499   0.0  \n",
       "9996  0.036356  0.037387  0.039391  0.037296  0.036356  0.037387   0.0  \n",
       "9997  0.051098  0.049133  0.047217  0.047710  0.051098  0.049133   0.0  \n",
       "9998  0.024976  0.025639  0.025219  0.024221  0.024976  0.025639   0.0  \n",
       "9999  0.046743  0.044648  0.044209  0.044828  0.046743  0.044648   0.0  \n",
       "\n",
       "[17820 rows x 2103 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.concat([df_sample1,df_sample2])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6a39c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['2048', '2049', '2050','2051','2052','2053'], axis=1)\n",
    "df = df.dropna()\n",
    "df = df[df['2102'] != 2102.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a024d1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0533fa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"2102\",axis=1)\n",
    "Y=df[\"2102\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a6820ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19bddeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "sss.get_n_splits(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a5e8aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=sss.split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "607cd664",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"2102\",axis=1)\n",
    "Y=df[\"2102\"]\n",
    "seed = 1\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a2c55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b2ec756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1529539",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_rf = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91de2278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7251576d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a1ff246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8698092031425365"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b31b362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4ec0501d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.8698092031425365%\n"
     ]
    }
   ],
   "source": [
    "acc_rf = accuracy_score(y_test,y_preds_rf)\n",
    "print('Accuracy of the model: {0}%'.format(acc_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "92dc16f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.8379888268156426%\n"
     ]
    }
   ],
   "source": [
    "f1_rf = f1_score(y_test,y_preds_rf)\n",
    "print('F1 score of the model: {0}%'.format(f1_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1ddc21c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model: 0.8379888268156426%\n"
     ]
    }
   ],
   "source": [
    "rec_rf = recall_score(y_test,y_preds_rf)\n",
    "print('Recall of the model: {0}%'.format(f1_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "56831ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.8379888268156426%\n"
     ]
    }
   ],
   "source": [
    "pre_rf = precision_score(y_test,y_preds_rf)\n",
    "print('Precision of the model: {0}%'.format(f1_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54a9972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ff2cf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toghrul/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c164cb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.819304152637486"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40460346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8822250280583613"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9d2728fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_log_reg = log_reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f37c9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_log_reg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2ace19a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.819304152637486%\n"
     ]
    }
   ],
   "source": [
    "acc_log_reg = accuracy_score(y_test,y_preds_log_reg)\n",
    "print('Accuracy of the model: {0}%'.format(acc_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "440e4929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.7873183619550859%\n"
     ]
    }
   ],
   "source": [
    "f1_log_reg = f1_score(y_test,y_preds_log_reg)\n",
    "print('F1 score of the model: {0}%'.format(f1_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "af8dc3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model: 0.7376237623762376%\n"
     ]
    }
   ],
   "source": [
    "rec_log_reg = recall_score(y_test,y_preds_log_reg)\n",
    "print('Recall of the model: {0}%'.format(rec_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5150d29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.8441926345609065%\n"
     ]
    }
   ],
   "source": [
    "pre_log_reg = precision_score(y_test,y_preds_log_reg)\n",
    "print('Precision of the model: {0}%'.format(pre_log_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7df8fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca955267",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b6626767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d2f7705",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_knn = KNN.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddd3bf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_knn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd5eb3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8920454545454546"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c79369c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8282828282828283"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d4a46a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.8282828282828283%\n"
     ]
    }
   ],
   "source": [
    "acc_KNN = accuracy_score(y_test,y_preds_knn)\n",
    "print('Accuracy of the model: {0}%'.format(acc_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d91cfee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.799475753604194%\n"
     ]
    }
   ],
   "source": [
    "f1_KNN = f1_score(y_test,y_preds_knn)\n",
    "print('F1 score of the model: {0}%'.format(f1_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d440c6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model: 0.754950495049505%\n"
     ]
    }
   ],
   "source": [
    "rec_KNN = recall_score(y_test,y_preds_knn)\n",
    "print('Recall of the model: {0}%'.format(rec_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5501b536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.8495821727019499%\n"
     ]
    }
   ],
   "source": [
    "pre_KNN = precision_score(y_test,y_preds_knn)\n",
    "print('Precision of the model: {0}%'.format(pre_KNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23a9d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "decision_tree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4a4840e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9553fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_ds = decision_tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "711a38a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0.,\n",
       "       1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1a70a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51646094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7530864197530864"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_tree.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "25f3b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.7530864197530864%\n"
     ]
    }
   ],
   "source": [
    "acc_decision_tree = accuracy_score(y_test,y_preds_ds)\n",
    "print('Accuracy of the model: {0}%'.format(acc_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7828e087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.7349397590361446%\n"
     ]
    }
   ],
   "source": [
    "f1_decision_tree = f1_score(y_test,y_preds_ds)\n",
    "print('F1 score of the model: {0}%'.format(f1_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a4ae531e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model: 0.754950495049505%\n"
     ]
    }
   ],
   "source": [
    "rec_decision_tree = recall_score(y_test,y_preds_ds)\n",
    "print('Recall of the model: {0}%'.format(rec_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fb8091c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.715962441314554%\n"
     ]
    }
   ],
   "source": [
    "pre_decision_tree = precision_score(y_test,y_preds_ds)\n",
    "print('Precision of the model: {0}%'.format(pre_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cfa3b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "143e759b",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()\n",
    "linear_svm = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff47f682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4fada9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toghrul/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6a47830b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8850308641975309"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df3980c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_svc = svc.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f5068f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_svc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "25753c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.8540965207631874%\n"
     ]
    }
   ],
   "source": [
    "acc_svc = accuracy_score(y_test,y_preds_svc)\n",
    "print('Accuracy of the model: {0}%'.format(acc_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8a2594a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.8121387283236994%\n"
     ]
    }
   ],
   "source": [
    "f1_svc = f1_score(y_test,y_preds_svc)\n",
    "print('F1 score of the model: {0}%'.format(f1_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6a6fef88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score of the model: 0.6955445544554455%\n"
     ]
    }
   ],
   "source": [
    "rec_svc = recall_score(y_test,y_preds_svc)\n",
    "print('Recall score of the model: {0}%'.format(rec_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "12354a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.9756944444444444%\n"
     ]
    }
   ],
   "source": [
    "pre_svc = precision_score(y_test,y_preds_svc)\n",
    "print('Precision of the model: {0}%'.format(pre_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7bef0b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8929573512906847"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_svm.score(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c9819d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_linear_svc = linear_svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7d9a2faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds_linear_svc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "244f40ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.8271604938271605%\n"
     ]
    }
   ],
   "source": [
    "acc_linear_svc = accuracy_score(y_test,y_preds_linear_svc)\n",
    "print('Accuracy of the model: {0}%'.format(acc_linear_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "168fe978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.7989556135770235%\n"
     ]
    }
   ],
   "source": [
    "f1_linear_svc = f1_score(y_test,y_preds_linear_svc)\n",
    "print('F1 score of the model: {0}%'.format(f1_linear_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b8cac1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model: 0.7574257425742574%\n"
     ]
    }
   ],
   "source": [
    "rec_linear_svc = recall_score(y_test,y_preds_linear_svc)\n",
    "print('Recall of the model: {0}%'.format(rec_linear_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "fa310e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.8453038674033149%\n"
     ]
    }
   ],
   "source": [
    "pre_linear_svc = precision_score(y_test,y_preds_linear_svc)\n",
    "print('Precision of the model: {0}%'.format(pre_linear_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b5075489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>86.980920</td>\n",
       "      <td>74.257426</td>\n",
       "      <td>96.153846</td>\n",
       "      <td>83.798883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>85.409652</td>\n",
       "      <td>69.554455</td>\n",
       "      <td>97.569444</td>\n",
       "      <td>81.213873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighbour Clasifier</td>\n",
       "      <td>82.828283</td>\n",
       "      <td>75.495050</td>\n",
       "      <td>84.958217</td>\n",
       "      <td>79.947575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>82.716049</td>\n",
       "      <td>75.742574</td>\n",
       "      <td>84.530387</td>\n",
       "      <td>79.895561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>81.930415</td>\n",
       "      <td>73.762376</td>\n",
       "      <td>84.419263</td>\n",
       "      <td>78.731836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>75.308642</td>\n",
       "      <td>75.495050</td>\n",
       "      <td>71.596244</td>\n",
       "      <td>73.493976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model   Accuracy     Recall  Precision   F1 score\n",
       "0  Random Forest Classifier  86.980920  74.257426  96.153846  83.798883\n",
       "4                       SVC  85.409652  69.554455  97.569444  81.213873\n",
       "2      KNeighbour Clasifier  82.828283  75.495050  84.958217  79.947575\n",
       "5                Linear SVC  82.716049  75.742574  84.530387  79.895561\n",
       "1       Logistic Regression  81.930415  73.762376  84.419263  78.731836\n",
       "3             Decision Tree  75.308642  75.495050  71.596244  73.493976"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Models = pd.DataFrame({\n",
    "    'Model' : ['Random Forest Classifier', 'Logistic Regression', 'KNeighbour Clasifier',\n",
    "              'Decision Tree', 'SVC', 'Linear SVC'],\n",
    "    'Accuracy' : [acc_rf, acc_log_reg, acc_KNN, acc_decision_tree, acc_svc, acc_linear_svc],\n",
    "    'Recall' : [rec_rf, rec_log_reg, rec_KNN, rec_decision_tree, rec_svc, rec_linear_svc],\n",
    "    'Precision' : [pre_rf, pre_log_reg, pre_KNN, pre_decision_tree, pre_svc, pre_linear_svc],\n",
    "    'F1 score' : [f1_rf, f1_log_reg, f1_KNN, f1_decision_tree, f1_svc, f1_linear_svc]\n",
    "})\n",
    "Models.sort_values(by = \"F1 score\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0f3aad38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Models.sort_values(by = \"F1 score\", ascending = False).plot(kind = \"bar\", color = [\"blue\", 'red','green','yellow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdff762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0860b722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['0'] = df['0'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ce3e457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "24d172ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight=int(y_train.value_counts()[0]/y_train.value_counts()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0bfff876",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost=xgb.XGBClassifier(scale_pos_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "698bd520",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_param_grid={\n",
    "    'learning_rate':[0.05,0.1,0.15,0.2,0.25,0.3],\n",
    "    'max_depth'    :[1,2,3,4,5,6,7,8,9,10],\n",
    "    'min_child_weight':[1,3,5,7],\n",
    "    'colsample_bytree':[0.3,0.4,0.5,0.6,0.7],\n",
    "    'gamma':[0.0,0.1,0.2,0.3,0.4,0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "598aa5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2b6687a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve,KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3029cac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold=StratifiedKFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d4bd393a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gsXGoost=RandomizedSearchCV(estimator=XGBoost,param_distributions=xgboost_param_grid,random_state=3,scoring = \"roc_auc\", \n",
    "                                     cv =kfold,n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2e8b6042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           import...\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                   n_jobs=1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5, 0.6,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                                        'learning_rate': [0.05, 0.1, 0.15, 0.2,\n",
       "                                                          0.25, 0.3],\n",
       "                                        'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10],\n",
       "                                        'min_child_weight': [1, 3, 5, 7]},\n",
       "                   random_state=3, scoring='roc_auc')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsXGoost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5c40447f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9189727018975496"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBOOST_best = gsXGoost.best_estimator_\n",
    "\n",
    "# Best score\n",
    "gsXGoost.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ac5caffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = XGBOOST_best.predict(X_test)\n",
    "y_pred = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b5c707b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8821548821548821"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0249c04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.859437751004016"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "74e4238e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 0.8821548821548821%\n"
     ]
    }
   ],
   "source": [
    "acc_xgboost = accuracy_score(y_test,y_pred)\n",
    "print('Accuracy of the model: {0}%'.format(acc_xgboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e07445a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of the model: 0.9358600583090378%\n"
     ]
    }
   ],
   "source": [
    "pre_xgboost = precision_score(y_test,y_pred)\n",
    "print('Precision of the model: {0}%'.format(pre_xgboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c0bdefb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model: 0.7945544554455446%\n"
     ]
    }
   ],
   "source": [
    "rec_xgboost = recall_score(y_test,y_pred)\n",
    "print('Recall of the model: {0}%'.format(rec_xgboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2b2573a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the model: 0.859437751004016%\n"
     ]
    }
   ],
   "source": [
    "f1_xgboost = f1_score(y_test,y_pred)\n",
    "print('F1 score of the model: {0}%'.format(f1_xgboost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8881a7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.882155</td>\n",
       "      <td>0.794554</td>\n",
       "      <td>0.935860</td>\n",
       "      <td>0.859438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.869809</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.837989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.854097</td>\n",
       "      <td>0.695545</td>\n",
       "      <td>0.975694</td>\n",
       "      <td>0.812139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighbour Clasifier</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.754950</td>\n",
       "      <td>0.849582</td>\n",
       "      <td>0.799476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.819304</td>\n",
       "      <td>0.737624</td>\n",
       "      <td>0.844193</td>\n",
       "      <td>0.787318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.754950</td>\n",
       "      <td>0.715962</td>\n",
       "      <td>0.734940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Accuracy    Recall  Precision  F1 score\n",
       "5                   XGBoost  0.882155  0.794554   0.935860  0.859438\n",
       "0  Random Forest Classifier  0.869809  0.742574   0.961538  0.837989\n",
       "4                       SVC  0.854097  0.695545   0.975694  0.812139\n",
       "2      KNeighbour Clasifier  0.828283  0.754950   0.849582  0.799476\n",
       "1       Logistic Regression  0.819304  0.737624   0.844193  0.787318\n",
       "3             Decision Tree  0.753086  0.754950   0.715962  0.734940"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Models = pd.DataFrame({\n",
    "    'Model' : ['Random Forest Classifier', 'Logistic Regression', 'KNeighbour Clasifier',\n",
    "              'Decision Tree', 'SVC', 'XGBoost'],\n",
    "    'Accuracy' : [acc_rf, acc_log_reg, acc_KNN, acc_decision_tree, acc_svc,acc_xgboost],\n",
    "    'Recall' : [rec_rf, rec_log_reg, rec_KNN, rec_decision_tree, rec_svc,rec_xgboost],\n",
    "    'Precision' : [pre_rf, pre_log_reg, pre_KNN, pre_decision_tree, pre_svc,pre_xgboost],\n",
    "    'F1 score' : [f1_rf, f1_log_reg, f1_KNN, f1_decision_tree, f1_svc, f1_xgboost]\n",
    "})\n",
    "Models.sort_values(by = \"F1 score\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9a522588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Models.sort_values(by = \"F1 score\", ascending = False).plot(kind = \"bar\", color = [\"blue\", 'red','green','yellow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efce02e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "b2816c58",
   "metadata": {},
   "source": [
    "# build the lightgbm model\n",
    "import lightgbm as lgb\n",
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "afd2ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the results\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db3b668c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model accuracy score: 0.8687\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# view accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_pred, y_test)\n",
    "print('LightGBM Model accuracy score: {0:0.4f}'.format(accuracy_score(y_test, y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "324849a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[463  24]\n",
      " [ 93 311]]\n",
      "\n",
      "True Positives(TP) =  463\n",
      "\n",
      "True Negatives(TN) =  311\n",
      "\n",
      "False Positives(FP) =  24\n",
      "\n",
      "False Negatives(FN) =  93\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# view confusion-matrix\n",
    "# Print the Confusion Matrix and slice it into four pieces\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
    "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
    "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
    "print('\\nFalse Negatives(FN) = ', cm[1,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f8623d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.95      0.89       487\n",
      "         1.0       0.93      0.77      0.84       404\n",
      "\n",
      "    accuracy                           0.87       891\n",
      "   macro avg       0.88      0.86      0.86       891\n",
      "weighted avg       0.88      0.87      0.87       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ca413047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8416779431664412"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c8ec4f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8686868686868687"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb99f361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
